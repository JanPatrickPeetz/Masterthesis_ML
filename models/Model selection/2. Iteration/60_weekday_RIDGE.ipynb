{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for linear regression\n",
    "\n",
    "# ridge parameters for random search\n",
    "fit_intercept = [True, False]\n",
    "copy_X = [True, False]\n",
    "alpha = [0.1, 0.5, 1, 2, 5, 10, 20, 50, 100]\n",
    "tol = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "solver = ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'fit_intercept': fit_intercept,\n",
    "                'copy_X': copy_X,\n",
    "                'alpha': alpha,\n",
    "                'tol': tol,\n",
    "                'solver': solver}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define MASE Metric\n",
    "def mean_absolute_scaled_error(y_true, y_pred):\n",
    "    mase=0\n",
    "    # Define numerator as the forecast error\n",
    "    numerator = (np.abs(y_true - y_pred))\n",
    "\n",
    "    # Define denominator as the mean absolute error of the in-sample one-step naive forecast\n",
    "    y_true_ohne_1 = y_true[1:].reset_index(drop=True)\n",
    "    y_true_ohne_ende = y_true[:-1].reset_index(drop=True)\n",
    "    denominator = np.mean(np.abs(y_true_ohne_1 - y_true_ohne_ende))\n",
    "\n",
    "    mase = np.mean(np.abs(numerator / denominator))\n",
    "\n",
    "    return mase\n",
    "\n",
    "scorer_mase= make_scorer(mean_absolute_scaled_error, greater_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_parquet('/Users/paddy/Documents/GitHub/Masterthesis_ML/data/03_032022_032023_taxi_rides.parquet')\n",
    "\n",
    "# Convert the date column to datetime\n",
    "data['date'] = pd.to_datetime(data['date']) #,format='%d/%m/%y %H:%M:%S').dt.strftime('%Y-%m-%d %H:%M:%S') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering\n",
    "# Create a new column for the time\n",
    "data['time'] = [x for x in range(0, len(data))]\n",
    "\n",
    "data['hour_of_day'] = data['date'].dt.hour\n",
    "data['day_of_week'] = data['date'].dt.dayofweek\n",
    "data['day_of_month'] = data['date'].dt.day\n",
    "data['month_of_year'] = data['date'].dt.month\n",
    "data['year'] = data['date'].dt.year\n",
    "\n",
    "# make a weekend column\n",
    "data['weekend'] = 0\n",
    "data.loc[data['day_of_week'] == 5, 'weekend'] = 1\n",
    "data.loc[data['day_of_week'] == 6, 'weekend'] = 1\n",
    "\n",
    "#make a monday column\n",
    "data['monday'] = 0\n",
    "data.loc[data['day_of_week'] == 0, 'monday'] = 1\n",
    "\n",
    "#make a tuesday column\n",
    "data['tuesday'] = 0\n",
    "data.loc[data['day_of_week'] == 1, 'tuesday'] = 1\n",
    "\n",
    "#make a wednesday column\n",
    "data['wednesday'] = 0\n",
    "data.loc[data['day_of_week'] == 2, 'wednesday'] = 1\n",
    "\n",
    "#make a thursday column\n",
    "data['thursday'] = 0\n",
    "data.loc[data['day_of_week'] == 3, 'thursday'] = 1\n",
    "\n",
    "#make a friday column\n",
    "data['friday'] = 0\n",
    "data.loc[data['day_of_week'] == 4, 'friday'] = 1\n",
    "\n",
    "#make a saturday column\n",
    "data['saturday'] = 0\n",
    "data.loc[data['day_of_week'] == 5, 'saturday'] = 1\n",
    "\n",
    "#make a sunday column\n",
    "data['sunday'] = 0\n",
    "data.loc[data['day_of_week'] == 6, 'sunday'] = 1\n",
    "\n",
    "\n",
    "# Drop the first three rows\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "# Define the feature columns and the target column\n",
    "feature_cols = ['time', 'hour_of_day', 'day_of_week', 'day_of_month', 'month_of_year', 'year', 'weekend', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "target_col = 'y'\n",
    "\n",
    "# Drop nan values\n",
    "data = data.dropna()\n",
    "\n",
    "# Rename column count to y\n",
    "data = data.rename(columns={'count': 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set y to the last column\n",
    "cols = list(data.columns.values) #Make a list of all of the columns in the df\n",
    "cols.pop(cols.index('y')) #Remove y from list\n",
    "data = data[cols+['y']] #Create new dataframe with columns in the order you want\n",
    "\n",
    "# drop the date column\n",
    "train_data = np.delete(data, 0, 1) \n",
    "\n",
    "# Split the data into X and y\n",
    "X_train, y_train = train_data[:, :-1], train_data[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgl: https://lightrun.com/answers/scikit-learn-scikit-learn-grid_search-feeding-parameters-to-scorer-functions\n",
    "\n",
    "# X and y to pandas dataframe\n",
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = pd.Series(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Cross Validation to 5 iterations\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = Ridge()\n",
    "\n",
    "search = RandomizedSearchCV(estimator = model, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 25, \n",
    "                               cv = tscv,\n",
    "                               refit=True, \n",
    "                               verbose=3, \n",
    "                               random_state=42, \n",
    "                               n_jobs = -1, \n",
    "                               scoring=scorer_mase, #make_scorer(scorer_mase, greater_is_better=True), #'neg_root_mean_squared_error', #\n",
    "                               error_score=np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 4/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=0.001;, score=-0.992 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=0.001;, score=-1.387 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=cholesky, tol=0.01;, score=-1.117 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=0.001;, score=-1.116 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=cholesky, tol=0.01;, score=-1.646 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=cholesky, tol=0.01;, score=-0.937 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=0.001;, score=-1.060 total time=   0.0s\n",
      "[CV 1/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=0.1;, score=-1.118 total time=   0.0s\n",
      "[CV 2/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=0.1;, score=-1.387 total time=   0.0s\n",
      "[CV 3/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=0.1;, score=-1.060 total time=   0.0s\n",
      "[CV 4/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=0.1;, score=-0.991 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=0.001;, score=-0.937 total time=   0.0s\n",
      "[CV 5/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=0.1;, score=-0.938 total time=   0.0s\n",
      "[CV 1/5] END alpha=50, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.691 total time=   0.0s\n",
      "[CV 2/5] END alpha=50, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.658 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=cholesky, tol=0.01;, score=-1.399 total time=   0.0s\n",
      "[CV 3/5] END alpha=50, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.424 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=cholesky, tol=0.01;, score=-1.061 total time=   0.0s\n",
      "[CV 4/5] END alpha=50, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.300 total time=   0.0s\n",
      "[CV 5/5] END alpha=50, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.258 total time=   0.0s\n",
      "[CV 1/5] END alpha=20, copy_X=False, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.132 total time=   0.0s\n",
      "[CV 2/5] END alpha=20, copy_X=False, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.398 total time=   0.0s\n",
      "[CV 3/5] END alpha=20, copy_X=False, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.067 total time=   0.0s\n",
      "[CV 4/5] END alpha=20, copy_X=False, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.015 total time=   0.0s\n",
      "[CV 1/5] END alpha=2, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.01;, score=-1.460 total time=   0.0s\n",
      "[CV 5/5] END alpha=20, copy_X=False, fit_intercept=True, solver=lsqr, tol=0.001;, score=-0.958 total time=   0.0s\n",
      "[CV 2/5] END alpha=2, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.01;, score=-1.666 total time=   0.0s\n",
      "[CV 3/5] END alpha=2, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.01;, score=-1.349 total time=   0.0s\n",
      "[CV 4/5] END alpha=2, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.01;, score=-1.300 total time=   0.0s\n",
      "[CV 5/5] END alpha=2, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.01;, score=-1.260 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=False, fit_intercept=True, solver=sag, tol=1;, score=-1.378 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=False, fit_intercept=True, solver=sag, tol=1;, score=-1.627 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=False, fit_intercept=True, solver=sag, tol=1;, score=-1.422 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=False, fit_intercept=True, solver=sag, tol=1;, score=-1.317 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=False, fit_intercept=True, solver=sag, tol=1;, score=-1.262 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=False, fit_intercept=False, solver=saga, tol=10;, score=-1.490 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=False, fit_intercept=False, solver=saga, tol=10;, score=-1.655 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=False, fit_intercept=False, solver=saga, tol=10;, score=-1.505 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=False, fit_intercept=False, solver=saga, tol=10;, score=-1.324 total time=   0.0s\n",
      "[CV 1/5] END alpha=100, copy_X=False, fit_intercept=True, solver=sag, tol=0.0001;, score=-1.121 total time=   0.1s\n",
      "[CV 5/5] END alpha=10, copy_X=False, fit_intercept=False, solver=saga, tol=10;, score=-1.342 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=True, fit_intercept=False, solver=svd, tol=0.01;, score=-1.117 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=True, fit_intercept=False, solver=svd, tol=0.01;, score=-1.394 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=True, fit_intercept=False, solver=svd, tol=0.01;, score=-1.060 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=True, fit_intercept=False, solver=svd, tol=0.01;, score=-1.290 total time=   0.0s\n",
      "[CV 1/5] END alpha=100, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=1;, score=-2.133 total time=   0.0s\n",
      "[CV 2/5] END alpha=100, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=1;, score=-1.976 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=True, fit_intercept=False, solver=svd, tol=0.01;, score=-0.937 total time=   0.0s\n",
      "[CV 3/5] END alpha=100, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=1;, score=-1.659 total time=   0.0s\n",
      "[CV 4/5] END alpha=100, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=1;, score=-1.903 total time=   0.0s\n",
      "[CV 5/5] END alpha=100, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=1;, score=-1.888 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.5, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.454 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.5, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.891 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.5, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.352 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.5, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.488 total time=   0.0s\n",
      "[CV 1/5] END alpha=5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.132 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.5, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.318 total time=   0.0s\n",
      "[CV 2/5] END alpha=5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.398 total time=   0.0s\n",
      "[CV 3/5] END alpha=5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.067 total time=   0.0s\n",
      "[CV 4/5] END alpha=5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.015 total time=   0.0s\n",
      "[CV 5/5] END alpha=5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.001;, score=-0.958 total time=   0.0s\n",
      "[CV 1/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sag, tol=10;, score=-1.422 total time=   0.0s\n",
      "[CV 2/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sag, tol=10;, score=-1.901 total time=   0.0s\n",
      "[CV 3/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sag, tol=10;, score=-1.586 total time=   0.0s\n",
      "[CV 2/5] END alpha=100, copy_X=False, fit_intercept=True, solver=sag, tol=0.0001;, score=-1.388 total time=   0.2s\n",
      "[CV 1/5] END alpha=20, copy_X=True, fit_intercept=False, solver=saga, tol=10;, score=-1.433 total time=   0.0s\n",
      "[CV 2/5] END alpha=20, copy_X=True, fit_intercept=False, solver=saga, tol=10;, score=-1.815 total time=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 4/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sag, tol=10;, score=-1.430 total time=   0.0s\n",
      "[CV 3/5] END alpha=20, copy_X=True, fit_intercept=False, solver=saga, tol=10;, score=-1.351 total time=   0.0s\n",
      "[CV 5/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sag, tol=10;, score=-1.434 total time=   0.0s\n",
      "[CV 4/5] END alpha=20, copy_X=True, fit_intercept=False, solver=saga, tol=10;, score=-1.400 total time=   0.0s\n",
      "[CV 5/5] END alpha=20, copy_X=True, fit_intercept=False, solver=saga, tol=10;, score=-1.345 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=saga, tol=0.001;, score=-1.128 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=False, fit_intercept=False, solver=lsqr, tol=0.001;, score=-1.132 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=saga, tol=0.001;, score=-1.398 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=False, fit_intercept=False, solver=lsqr, tol=0.001;, score=-1.398 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=False, fit_intercept=False, solver=lsqr, tol=0.001;, score=-1.067 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=False, fit_intercept=False, solver=lsqr, tol=0.001;, score=-1.260 total time=   0.0s\n",
      "[CV 1/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=1;, score=-1.118 total time=   0.0s\n",
      "[CV 2/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=1;, score=-1.387 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=False, fit_intercept=False, solver=lsqr, tol=0.001;, score=-1.300 total time=   0.0s\n",
      "[CV 4/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=1;, score=-0.991 total time=   0.0s\n",
      "[CV 3/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=1;, score=-1.060 total time=   0.0s\n",
      "[CV 5/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=1;, score=-0.938 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.5, copy_X=True, fit_intercept=False, solver=auto, tol=100;, score=-1.117 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.5, copy_X=True, fit_intercept=False, solver=auto, tol=100;, score=-1.061 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.5, copy_X=True, fit_intercept=False, solver=auto, tol=100;, score=-1.399 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.5, copy_X=True, fit_intercept=False, solver=auto, tol=100;, score=-1.646 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.5, copy_X=True, fit_intercept=False, solver=auto, tol=100;, score=-0.937 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, copy_X=True, fit_intercept=False, solver=cholesky, tol=0.01;, score=-1.117 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, copy_X=True, fit_intercept=False, solver=cholesky, tol=0.01;, score=-1.419 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, copy_X=True, fit_intercept=False, solver=cholesky, tol=0.01;, score=-1.061 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, copy_X=True, fit_intercept=False, solver=cholesky, tol=0.01;, score=-2.385 total time=   0.0s\n",
      "[CV 1/5] END alpha=20, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.001;, score=-1.132 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=saga, tol=0.001;, score=-1.071 total time=   0.1s\n",
      "[CV 2/5] END alpha=20, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.001;, score=-1.398 total time=   0.0s\n",
      "[CV 3/5] END alpha=20, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.001;, score=-1.349 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, copy_X=True, fit_intercept=False, solver=cholesky, tol=0.01;, score=-0.937 total time=   0.0s\n",
      "[CV 4/5] END alpha=20, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.001;, score=-1.300 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=saga, tol=0.001;, score=-1.019 total time=   0.1s\n",
      "[CV 5/5] END alpha=20, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.001;, score=-1.260 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.1;, score=-1.426 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.1;, score=-1.667 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.1;, score=-1.300 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.1;, score=-1.349 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.1;, score=-1.260 total time=   0.0s\n",
      "[CV 3/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=0.0001;, score=-1.067 total time=   0.0s\n",
      "[CV 1/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=0.0001;, score=-1.132 total time=   0.0s\n",
      "[CV 2/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=0.0001;, score=-1.398 total time=   0.0s\n",
      "[CV 4/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=0.0001;, score=-1.015 total time=   0.0s\n",
      "[CV 5/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=0.0001;, score=-0.958 total time=   0.0s\n",
      "[CV 3/5] END alpha=100, copy_X=False, fit_intercept=True, solver=sag, tol=0.0001;, score=-1.061 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=svd, tol=0.0001;, score=-1.117 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=svd, tol=0.0001;, score=-1.399 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=svd, tol=0.0001;, score=-1.061 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=svd, tol=0.0001;, score=-1.646 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=svd, tol=0.0001;, score=-0.937 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=100;, score=-1.425 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=100;, score=-1.662 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=100;, score=-1.349 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=100;, score=-1.302 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=100;, score=-1.261 total time=   0.0s\n",
      "[CV 4/5] END alpha=100, copy_X=False, fit_intercept=True, solver=sag, tol=0.0001;, score=-0.999 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=saga, tol=0.001;, score=-0.965 total time=   0.1s\n",
      "[CV 5/5] END alpha=100, copy_X=False, fit_intercept=True, solver=sag, tol=0.0001;, score=-0.945 total time=   0.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Ridge(), n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={&#x27;alpha&#x27;: [0.1, 0.5, 1, 2, 5, 10, 20, 50,\n",
       "                                                  100],\n",
       "                                        &#x27;copy_X&#x27;: [True, False],\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;solver&#x27;: [&#x27;auto&#x27;, &#x27;svd&#x27;, &#x27;cholesky&#x27;,\n",
       "                                                   &#x27;lsqr&#x27;, &#x27;sparse_cg&#x27;, &#x27;sag&#x27;,\n",
       "                                                   &#x27;saga&#x27;],\n",
       "                                        &#x27;tol&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10,\n",
       "                                                100]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(mean_absolute_scaled_error, greater_is_better=False),\n",
       "                   verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Ridge(), n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={&#x27;alpha&#x27;: [0.1, 0.5, 1, 2, 5, 10, 20, 50,\n",
       "                                                  100],\n",
       "                                        &#x27;copy_X&#x27;: [True, False],\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;solver&#x27;: [&#x27;auto&#x27;, &#x27;svd&#x27;, &#x27;cholesky&#x27;,\n",
       "                                                   &#x27;lsqr&#x27;, &#x27;sparse_cg&#x27;, &#x27;sag&#x27;,\n",
       "                                                   &#x27;saga&#x27;],\n",
       "                                        &#x27;tol&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10,\n",
       "                                                100]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(mean_absolute_scaled_error, greater_is_better=False),\n",
       "                   verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Ridge(), n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={'alpha': [0.1, 0.5, 1, 2, 5, 10, 20, 50,\n",
       "                                                  100],\n",
       "                                        'copy_X': [True, False],\n",
       "                                        'fit_intercept': [True, False],\n",
       "                                        'solver': ['auto', 'svd', 'cholesky',\n",
       "                                                   'lsqr', 'sparse_cg', 'sag',\n",
       "                                                   'saga'],\n",
       "                                        'tol': [0.0001, 0.001, 0.01, 0.1, 1, 10,\n",
       "                                                100]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(mean_absolute_scaled_error, greater_is_better=False),\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the random search model\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -1.0985381989598466\n",
      "Best Hyperparameters: {'tol': 0.001, 'solver': 'sparse_cg', 'fit_intercept': True, 'copy_X': False, 'alpha': 10}\n",
      "Best Model: Ridge(alpha=10, copy_X=False, solver='sparse_cg', tol=0.001)\n",
      "Best Index: 0\n",
      "CV Results: {'mean_fit_time': array([0.00449157, 0.00554686, 0.00503092, 0.00429177, 0.00372801,\n",
      "       0.00350785, 0.36218338, 0.00638213, 0.00579896, 0.00472193,\n",
      "       0.00389676, 0.00479636, 0.0055594 , 0.00512018, 0.00500011,\n",
      "       0.06680512, 0.00464463, 0.00524855, 0.0032032 , 0.00511203,\n",
      "       0.00439582, 0.00400567, 0.00518365, 0.005022  , 0.00354714]), 'std_fit_time': array([0.00110611, 0.00196298, 0.00058756, 0.00118661, 0.00093142,\n",
      "       0.00101167, 0.16974647, 0.00161049, 0.00285098, 0.00181697,\n",
      "       0.00163151, 0.00195395, 0.00209544, 0.00257013, 0.00353018,\n",
      "       0.04190347, 0.00208259, 0.00263072, 0.00101447, 0.0034351 ,\n",
      "       0.00175897, 0.00228418, 0.0025453 , 0.00099114, 0.00127039]), 'mean_score_time': array([0.00355096, 0.00340185, 0.00186133, 0.0019186 , 0.00179167,\n",
      "       0.00168343, 0.00175071, 0.00175247, 0.00184536, 0.00166025,\n",
      "       0.00158219, 0.00155206, 0.00156837, 0.00160141, 0.00235868,\n",
      "       0.0022285 , 0.00327568, 0.00212936, 0.00151582, 0.00153866,\n",
      "       0.00156817, 0.00153937, 0.00158696, 0.00156603, 0.00153127]), 'std_score_time': array([2.05769736e-03, 2.20967746e-03, 1.83228796e-04, 1.77151095e-04,\n",
      "       7.11790912e-05, 4.67576218e-05, 5.97269710e-05, 2.77856846e-04,\n",
      "       5.84014259e-04, 1.19913937e-04, 5.90156830e-05, 6.43926873e-05,\n",
      "       5.82753536e-05, 1.79052981e-04, 1.14463131e-03, 1.14092018e-03,\n",
      "       3.40543090e-03, 1.17371555e-03, 3.57002347e-05, 1.13853057e-04,\n",
      "       6.47975206e-05, 7.11343876e-05, 5.99005791e-05, 5.89337934e-05,\n",
      "       2.54447921e-05]), 'param_tol': masked_array(data=[0.001, 0.01, 0.1, 100, 0.001, 0.01, 0.0001, 1, 10,\n",
      "                   0.01, 1, 100, 0.001, 10, 10, 0.001, 0.001, 1, 100,\n",
      "                   0.01, 0.001, 0.1, 0.0001, 0.0001, 100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_solver': masked_array(data=['sparse_cg', 'cholesky', 'svd', 'saga', 'lsqr',\n",
      "                   'sparse_cg', 'sag', 'sag', 'saga', 'svd', 'sparse_cg',\n",
      "                   'saga', 'lsqr', 'sag', 'saga', 'saga', 'lsqr', 'svd',\n",
      "                   'auto', 'cholesky', 'sparse_cg', 'lsqr', 'sparse_cg',\n",
      "                   'svd', 'sparse_cg'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_fit_intercept': masked_array(data=[True, True, False, True, True, False, True, True,\n",
      "                   False, False, False, True, True, False, False, True,\n",
      "                   False, False, False, False, False, True, False, True,\n",
      "                   True],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_copy_X': masked_array(data=[False, True, False, False, False, False, False, False,\n",
      "                   False, True, True, False, True, True, True, True,\n",
      "                   False, False, True, True, False, True, True, True,\n",
      "                   False],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_alpha': masked_array(data=[10, 0.5, 100, 50, 20, 2, 100, 1, 10, 1, 100, 0.5, 5, 5,\n",
      "                   20, 0.5, 1, 100, 0.5, 0.1, 20, 0.5, 5, 0.5, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'tol': 0.001, 'solver': 'sparse_cg', 'fit_intercept': True, 'copy_X': False, 'alpha': 10}, {'tol': 0.01, 'solver': 'cholesky', 'fit_intercept': True, 'copy_X': True, 'alpha': 0.5}, {'tol': 0.1, 'solver': 'svd', 'fit_intercept': False, 'copy_X': False, 'alpha': 100}, {'tol': 100, 'solver': 'saga', 'fit_intercept': True, 'copy_X': False, 'alpha': 50}, {'tol': 0.001, 'solver': 'lsqr', 'fit_intercept': True, 'copy_X': False, 'alpha': 20}, {'tol': 0.01, 'solver': 'sparse_cg', 'fit_intercept': False, 'copy_X': False, 'alpha': 2}, {'tol': 0.0001, 'solver': 'sag', 'fit_intercept': True, 'copy_X': False, 'alpha': 100}, {'tol': 1, 'solver': 'sag', 'fit_intercept': True, 'copy_X': False, 'alpha': 1}, {'tol': 10, 'solver': 'saga', 'fit_intercept': False, 'copy_X': False, 'alpha': 10}, {'tol': 0.01, 'solver': 'svd', 'fit_intercept': False, 'copy_X': True, 'alpha': 1}, {'tol': 1, 'solver': 'sparse_cg', 'fit_intercept': False, 'copy_X': True, 'alpha': 100}, {'tol': 100, 'solver': 'saga', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.5}, {'tol': 0.001, 'solver': 'lsqr', 'fit_intercept': True, 'copy_X': True, 'alpha': 5}, {'tol': 10, 'solver': 'sag', 'fit_intercept': False, 'copy_X': True, 'alpha': 5}, {'tol': 10, 'solver': 'saga', 'fit_intercept': False, 'copy_X': True, 'alpha': 20}, {'tol': 0.001, 'solver': 'saga', 'fit_intercept': True, 'copy_X': True, 'alpha': 0.5}, {'tol': 0.001, 'solver': 'lsqr', 'fit_intercept': False, 'copy_X': False, 'alpha': 1}, {'tol': 1, 'solver': 'svd', 'fit_intercept': False, 'copy_X': False, 'alpha': 100}, {'tol': 100, 'solver': 'auto', 'fit_intercept': False, 'copy_X': True, 'alpha': 0.5}, {'tol': 0.01, 'solver': 'cholesky', 'fit_intercept': False, 'copy_X': True, 'alpha': 0.1}, {'tol': 0.001, 'solver': 'sparse_cg', 'fit_intercept': False, 'copy_X': False, 'alpha': 20}, {'tol': 0.1, 'solver': 'lsqr', 'fit_intercept': True, 'copy_X': True, 'alpha': 0.5}, {'tol': 0.0001, 'solver': 'sparse_cg', 'fit_intercept': False, 'copy_X': True, 'alpha': 5}, {'tol': 0.0001, 'solver': 'svd', 'fit_intercept': True, 'copy_X': True, 'alpha': 0.5}, {'tol': 100, 'solver': 'sparse_cg', 'fit_intercept': True, 'copy_X': False, 'alpha': 10}], 'split0_test_score': array([-1.11637682, -1.11654499, -1.11801014, -1.69129736, -1.13200087,\n",
      "       -1.45964719, -1.1212477 , -1.37806273, -1.49040333, -1.1165517 ,\n",
      "       -2.13275614, -1.45430089, -1.13197015, -1.42246434, -1.43328604,\n",
      "       -1.12833785, -1.13196717, -1.11801014, -1.11654498, -1.1165396 ,\n",
      "       -1.13200607, -1.4256819 , -1.13197536, -1.11654499, -1.42459744]), 'split1_test_score': array([-1.38692389, -1.39921096, -1.38727154, -1.65755485, -1.3984483 ,\n",
      "       -1.66608641, -1.38814225, -1.62698544, -1.65502308, -1.39396054,\n",
      "       -1.9762472 , -1.89078063, -1.39844092, -1.90075586, -1.81547903,\n",
      "       -1.39760063, -1.39844744, -1.38727154, -1.39921092, -1.41932996,\n",
      "       -1.39845679, -1.66696527, -1.39844941, -1.39921096, -1.66172943]), 'split2_test_score': array([-1.06039046, -1.06062952, -1.05988128, -1.42363093, -1.06676916,\n",
      "       -1.34920599, -1.06115195, -1.42170866, -1.50456836, -1.06043559,\n",
      "       -1.65860265, -1.35156589, -1.06676052, -1.58586065, -1.35111271,\n",
      "       -1.0712089 , -1.06676613, -1.05988128, -1.06062952, -1.06106081,\n",
      "       -1.34920599, -1.34928372, -1.06676844, -1.06062952, -1.34943756]), 'split3_test_score': array([-0.99184911, -1.64618573, -0.9905045 , -1.30029685, -1.01462041,\n",
      "       -1.30005612, -0.99928582, -1.31653852, -1.32361021, -1.28984829,\n",
      "       -1.90266473, -1.48807421, -1.01461289, -1.43002196, -1.39994363,\n",
      "       -1.01925397, -1.30005612, -0.9905045 , -1.64620417, -2.3853757 ,\n",
      "       -1.30005612, -1.30002588, -1.014619  , -1.64618573, -1.30165251]), 'split4_test_score': array([-0.93715071, -0.93704974, -0.93756315, -1.25832021, -0.9580921 ,\n",
      "       -1.260277  , -0.94510842, -1.26237646, -1.34188431, -0.93710793,\n",
      "       -1.88829525, -1.3181495 , -0.95808653, -1.43359056, -1.3454723 ,\n",
      "       -0.96537303, -1.260277  , -0.93756315, -0.93710544, -0.93710345,\n",
      "       -1.260277  , -1.26003702, -0.95809772, -0.93704974, -1.26068656]), 'mean_test_score': array([-1.0985382 , -1.23192419, -1.09864612, -1.46622004, -1.11398617,\n",
      "       -1.40705454, -1.10298723, -1.40113436, -1.46309786, -1.15958081,\n",
      "       -1.91171319, -1.50057422, -1.1139742 , -1.55453867, -1.46905874,\n",
      "       -1.11635488, -1.23150277, -1.09864612, -1.231939  , -1.3838819 ,\n",
      "       -1.2880004 , -1.40039876, -1.11398199, -1.23192419, -1.3996207 ]), 'std_test_score': array([0.15644057, 0.25659409, 0.15673203, 0.17879345, 0.15339439,\n",
      "       0.14574104, 0.15432221, 0.12519946, 0.12120249, 0.16314346,\n",
      "       0.15344044, 0.20495891, 0.15339357, 0.18353413, 0.17620924,\n",
      "       0.15066853, 0.11869586, 0.15673203, 0.25658724, 0.52526998,\n",
      "       0.09076882, 0.14428154, 0.15339329, 0.25659409, 0.14194621]), 'rank_test_score': array([ 1, 11,  2, 21,  7, 19,  4, 18, 20,  9, 25, 23,  5, 24, 22,  8, 10,\n",
      "        2, 13, 15, 14, 17,  6, 12, 16], dtype=int32)}\n",
      "Refit Time: 0.005034923553466797\n",
      "Scorer: make_scorer(mean_absolute_scaled_error, greater_is_better=False)\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: %s' % search.best_score_)\n",
    "print('Best Hyperparameters: %s' % search.best_params_)\n",
    "print('Best Model: %s' % search.best_estimator_)\n",
    "print('Best Index: %s' % search.best_index_)\n",
    "print('CV Results: %s' % search.cv_results_)\n",
    "print('Refit Time: %s' % search.refit_time_)\n",
    "print('Scorer: %s' % search.scorer_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
