{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for LASSO\n",
    "alpha = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "#max_iter = [500, 1000, 10000, 100000]\n",
    "selection = ['cyclic', 'random']\n",
    "fit_intercept = [True, False]\n",
    "tol = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "warm_start = [True, False]\n",
    "#positive = [True, False]\n",
    "#random_state = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "copy_X = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'alpha': alpha,\n",
    "               #'max_iter': max_iter,\n",
    "               'selection': selection,\n",
    "               'fit_intercept': fit_intercept,\n",
    "               'tol': tol,\n",
    "               'warm_start': warm_start,\n",
    "               #'positive': positive,\n",
    "               #'random_state': random_state,\n",
    "               'copy_X': copy_X}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define MASE Metric\n",
    "def mean_absolute_scaled_error(y_true, y_pred):\n",
    "    mase=0\n",
    "    # Define numerator as the forecast error\n",
    "    numerator = (np.abs(y_true - y_pred))\n",
    "\n",
    "    # Define denominator as the mean absolute error of the in-sample one-step naive forecast\n",
    "    y_true_ohne_1 = y_true[1:].reset_index(drop=True)\n",
    "    y_true_ohne_ende = y_true[:-1].reset_index(drop=True)\n",
    "    denominator = np.mean(np.abs(y_true_ohne_1 - y_true_ohne_ende))\n",
    "\n",
    "    mase = np.mean(np.abs(numerator / denominator))\n",
    "\n",
    "    return mase\n",
    "\n",
    "scorer_mase= make_scorer(mean_absolute_scaled_error, greater_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_parquet('/Users/paddy/Documents/GitHub/Masterthesis_ML/data/03_032022_032023_taxi_rides.parquet')\n",
    "\n",
    "# Convert the date column to datetime\n",
    "data['date'] = pd.to_datetime(data['date']) #,format='%d/%m/%y %H:%M:%S').dt.strftime('%Y-%m-%d %H:%M:%S') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering\n",
    "# Create a new column for the time\n",
    "data['time'] = [x for x in range(0, len(data))]\n",
    "\n",
    "data['hour_of_day'] = data['date'].dt.hour\n",
    "data['day_of_week'] = data['date'].dt.dayofweek\n",
    "data['day_of_month'] = data['date'].dt.day\n",
    "data['month_of_year'] = data['date'].dt.month\n",
    "data['year'] = data['date'].dt.year\n",
    "\n",
    "# make a weekend column\n",
    "data['weekend'] = 0\n",
    "data.loc[data['day_of_week'] == 5, 'weekend'] = 1\n",
    "data.loc[data['day_of_week'] == 6, 'weekend'] = 1\n",
    "\n",
    "#make a monday column\n",
    "data['monday'] = 0\n",
    "data.loc[data['day_of_week'] == 0, 'monday'] = 1\n",
    "\n",
    "#make a tuesday column\n",
    "data['tuesday'] = 0\n",
    "data.loc[data['day_of_week'] == 1, 'tuesday'] = 1\n",
    "\n",
    "#make a wednesday column\n",
    "data['wednesday'] = 0\n",
    "data.loc[data['day_of_week'] == 2, 'wednesday'] = 1\n",
    "\n",
    "#make a thursday column\n",
    "data['thursday'] = 0\n",
    "data.loc[data['day_of_week'] == 3, 'thursday'] = 1\n",
    "\n",
    "#make a friday column\n",
    "data['friday'] = 0\n",
    "data.loc[data['day_of_week'] == 4, 'friday'] = 1\n",
    "\n",
    "#make a saturday column\n",
    "data['saturday'] = 0\n",
    "data.loc[data['day_of_week'] == 5, 'saturday'] = 1\n",
    "\n",
    "#make a sunday column\n",
    "data['sunday'] = 0\n",
    "data.loc[data['day_of_week'] == 6, 'sunday'] = 1\n",
    "\n",
    "\n",
    "# Drop the first three rows\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "# Define the feature columns and the target column\n",
    "feature_cols = ['time', 'hour_of_day', 'day_of_week', 'day_of_month', 'month_of_year', 'year', 'weekend', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "target_col = 'y'\n",
    "\n",
    "# Drop nan values\n",
    "data = data.dropna()\n",
    "\n",
    "# Rename column count to y\n",
    "data = data.rename(columns={'count': 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set y to the last column\n",
    "cols = list(data.columns.values) #Make a list of all of the columns in the df\n",
    "cols.pop(cols.index('y')) #Remove y from list\n",
    "data = data[cols+['y']] #Create new dataframe with columns in the order you want\n",
    "\n",
    "# drop the date column\n",
    "train_data = np.delete(data, 0, 1) \n",
    "\n",
    "# Split the data into X and y\n",
    "X_train, y_train = train_data[:, :-1], train_data[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgl: https://lightrun.com/answers/scikit-learn-scikit-learn-grid_search-feeding-parameters-to-scorer-functions\n",
    "\n",
    "# X and y to pandas dataframe\n",
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = pd.Series(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Cross Validation to 5 iterations\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = Lasso()\n",
    "\n",
    "search = RandomizedSearchCV(estimator = model, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 25, \n",
    "                               cv = tscv,\n",
    "                               refit=True, \n",
    "                               verbose=3, \n",
    "                               random_state=42, \n",
    "                               n_jobs = -1, \n",
    "                               scoring=scorer_mase, #make_scorer(scorer_mase, greater_is_better=True), #'neg_root_mean_squared_error', #\n",
    "                               error_score=np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e+05, tolerance: 7.413e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.117 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.060 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.001, copy_X=True, fit_intercept=True, selection=random, tol=10, warm_start=True;, score=-0.992 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.387 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=cyclic, tol=10, warm_start=True;, score=-1.131 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, copy_X=True, fit_intercept=True, selection=random, tol=10, warm_start=True;, score=-1.243 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=cyclic, tol=10, warm_start=True;, score=-1.390 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=cyclic, tol=10, warm_start=True;, score=-1.063 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, copy_X=True, fit_intercept=True, selection=random, tol=10, warm_start=True;, score=-1.650 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=cyclic, tol=10, warm_start=True;, score=-0.994 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=cyclic, tol=10, warm_start=True;, score=-0.940 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.178 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, copy_X=True, fit_intercept=True, selection=random, tol=10, warm_start=True;, score=-1.060 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.422 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.099 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, copy_X=True, fit_intercept=True, selection=random, tol=10, warm_start=True;, score=-1.416 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-0.937 total time=   0.1s\n",
      "[CV 4/5] END alpha=10, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.046 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-0.989 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-0.990 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.137 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.397 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.067 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.007 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-0.953 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.01, warm_start=True;, score=-1.137 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.01, warm_start=True;, score=-1.397 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.01, warm_start=True;, score=-1.067 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.01, warm_start=True;, score=-1.007 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, copy_X=False, fit_intercept=True, selection=random, tol=0.1, warm_start=False;, score=-1.117 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.01, warm_start=True;, score=-0.953 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, copy_X=False, fit_intercept=True, selection=random, tol=0.1, warm_start=False;, score=-1.387 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, copy_X=False, fit_intercept=True, selection=random, tol=0.1, warm_start=False;, score=-1.060 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, copy_X=False, fit_intercept=True, selection=random, tol=0.1, warm_start=False;, score=-1.002 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, copy_X=False, fit_intercept=True, selection=random, tol=0.1, warm_start=False;, score=-0.937 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, copy_X=True, fit_intercept=False, selection=cyclic, tol=0.01, warm_start=False;, score=-1.117 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-3.185 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-3.040 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-2.119 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-1.890 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, copy_X=True, fit_intercept=False, selection=cyclic, tol=0.01, warm_start=False;, score=-1.388 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-1.656 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, copy_X=False, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.199 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, copy_X=False, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.614 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, copy_X=True, fit_intercept=False, selection=cyclic, tol=0.01, warm_start=False;, score=-1.060 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.1, copy_X=False, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.211 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, copy_X=False, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-0.997 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=False, fit_intercept=False, selection=random, tol=0.001, warm_start=True;, score=-1.136 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, copy_X=False, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-0.923 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=False, fit_intercept=False, selection=random, tol=0.001, warm_start=True;, score=-1.397 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=False, fit_intercept=False, selection=random, tol=0.001, warm_start=True;, score=-1.067 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=False, fit_intercept=False, selection=random, tol=0.001, warm_start=True;, score=-0.953 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=False, fit_intercept=True, selection=random, tol=0.001, warm_start=False;, score=-1.396 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=False, fit_intercept=True, selection=random, tol=0.001, warm_start=False;, score=-1.137 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=False, fit_intercept=False, selection=random, tol=0.001, warm_start=True;, score=-1.007 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=False, fit_intercept=True, selection=random, tol=0.001, warm_start=False;, score=-1.067 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=False, fit_intercept=True, selection=random, tol=0.001, warm_start=False;, score=-1.007 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, copy_X=True, fit_intercept=False, selection=cyclic, tol=0.01, warm_start=False;, score=-1.170 total time=   0.1s\n",
      "[CV 5/5] END alpha=1, copy_X=False, fit_intercept=True, selection=random, tol=0.001, warm_start=False;, score=-0.953 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, copy_X=True, fit_intercept=False, selection=cyclic, tol=0.01, warm_start=False;, score=-0.937 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=random, tol=1, warm_start=True;, score=-1.388 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=random, tol=0.01, warm_start=False;, score=-1.116 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=random, tol=1, warm_start=True;, score=-1.060 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=random, tol=1, warm_start=True;, score=-0.993 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=random, tol=1, warm_start=True;, score=-0.944 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=True;, score=-1.178 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=True;, score=-1.422 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=True;, score=-1.099 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=True;, score=-1.046 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=True;, score=-0.990 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=random, tol=10, warm_start=False;, score=-1.119 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=random, tol=10, warm_start=False;, score=-1.387 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=random, tol=10, warm_start=False;, score=-1.002 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=random, tol=0.01, warm_start=False;, score=-1.386 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=random, tol=0.01, warm_start=False;, score=-1.060 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=random, tol=10, warm_start=False;, score=-0.939 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=random, tol=10, warm_start=False;, score=-1.060 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.075e+05, tolerance: 7.413e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e+05, tolerance: 1.525e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.062e+05, tolerance: 2.239e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.071e+05, tolerance: 2.977e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.118e+05, tolerance: 3.807e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+05, tolerance: 7.413e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.986e+05, tolerance: 2.239e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e+05, tolerance: 7.413e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=cyclic, tol=0.0001, warm_start=False;, score=-1.117 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=True, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.223 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=True, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.662 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=cyclic, tol=0.0001, warm_start=False;, score=-1.387 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=cyclic, tol=1, warm_start=False;, score=-1.387 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=cyclic, tol=0.0001, warm_start=False;, score=-0.937 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=True, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.026 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=cyclic, tol=1, warm_start=False;, score=-1.060 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=cyclic, tol=1, warm_start=False;, score=-1.117 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=cyclic, tol=1, warm_start=False;, score=-0.993 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=random, tol=0.01, warm_start=False;, score=-0.937 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=cyclic, tol=1, warm_start=False;, score=-0.937 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=random, tol=1, warm_start=True;, score=-1.122 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=False, fit_intercept=False, selection=random, tol=0.0001, warm_start=False;, score=-1.179 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=random, tol=0.01, warm_start=False;, score=-0.985 total time=   0.1s\n",
      "[CV 2/5] END alpha=10, copy_X=False, fit_intercept=False, selection=random, tol=0.0001, warm_start=False;, score=-1.423 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=False;, score=-1.117 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=False, fit_intercept=False, selection=random, tol=0.0001, warm_start=False;, score=-1.099 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=False, fit_intercept=False, selection=random, tol=0.0001, warm_start=False;, score=-0.989 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=False, fit_intercept=False, selection=random, tol=0.0001, warm_start=False;, score=-1.046 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=1, warm_start=False;, score=-1.343 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=1, warm_start=False;, score=-1.006 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=cyclic, tol=0.0001, warm_start=False;, score=-1.060 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=False;, score=-0.989 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.116 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=1, warm_start=False;, score=-0.954 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=False;, score=-1.389 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.0001, warm_start=True;, score=-1.116 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.386 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.0001, warm_start=True;, score=-1.386 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=cyclic, tol=0.0001, warm_start=False;, score=-1.039 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.961e+05, tolerance: 3.807e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+05, tolerance: 2.905e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.042e+05, tolerance: 2.239e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.067e+05, tolerance: 1.171e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.074e+05, tolerance: 7.413e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e+05, tolerance: 5.920e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+05, tolerance: 7.413e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e+05, tolerance: 1.525e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.071e+05, tolerance: 1.525e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.050e+05, tolerance: 2.977e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.959e+05, tolerance: 2.239e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.070e+05, tolerance: 2.977e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.062e+05, tolerance: 8.747e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.0001, warm_start=True;, score=-1.060 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.110 total time=   0.2s\n",
      "[CV 1/5] END alpha=10, copy_X=True, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-3.150 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=False;, score=-1.060 total time=   0.1s\n",
      "[CV 2/5] END alpha=10, copy_X=True, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-3.091 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.0001, warm_start=True;, score=-0.937 total time=   0.1s\n",
      "[CV 4/5] END alpha=10, copy_X=True, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-1.898 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=True, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-2.164 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.0001, warm_start=True;, score=-0.994 total time=   0.1s\n",
      "[CV 5/5] END alpha=10, copy_X=True, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-1.652 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.060 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.0001, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=False;, score=-0.937 total time=   0.2s\n",
      "[CV 1/5] END alpha=10, copy_X=True, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-3.302 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=True, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.661 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-0.937 total time=   0.1s\n",
      "[CV 1/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=1, warm_start=False;, score=-1.139 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=1, warm_start=False;, score=-1.398 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.904e+05, tolerance: 2.977e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.062e+05, tolerance: 2.239e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.116e+05, tolerance: 1.508e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.117e+05, tolerance: 3.807e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Lasso(), n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                  10],\n",
       "                                        &#x27;copy_X&#x27;: [True, False],\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;selection&#x27;: [&#x27;cyclic&#x27;, &#x27;random&#x27;],\n",
       "                                        &#x27;tol&#x27;: [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                10],\n",
       "                                        &#x27;warm_start&#x27;: [True, False]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(mean_absolute_scaled_error, greater_is_better=False),\n",
       "                   verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Lasso(), n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                  10],\n",
       "                                        &#x27;copy_X&#x27;: [True, False],\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;selection&#x27;: [&#x27;cyclic&#x27;, &#x27;random&#x27;],\n",
       "                                        &#x27;tol&#x27;: [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                10],\n",
       "                                        &#x27;warm_start&#x27;: [True, False]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(mean_absolute_scaled_error, greater_is_better=False),\n",
       "                   verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Lasso(), n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={'alpha': [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                  10],\n",
       "                                        'copy_X': [True, False],\n",
       "                                        'fit_intercept': [True, False],\n",
       "                                        'selection': ['cyclic', 'random'],\n",
       "                                        'tol': [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                10],\n",
       "                                        'warm_start': [True, False]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(mean_absolute_scaled_error, greater_is_better=False),\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the random search model\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -1.0968424665528325\n",
      "Best Hyperparameters: {'warm_start': False, 'tol': 0.01, 'selection': 'random', 'fit_intercept': False, 'copy_X': False, 'alpha': 0.01}\n",
      "Best Model: Lasso(alpha=0.01, copy_X=False, fit_intercept=False, selection='random',\n",
      "      tol=0.01)\n",
      "Best Index: 12\n",
      "CV Results: {'mean_fit_time': array([0.05541873, 0.01158276, 0.00422182, 0.00387402, 0.00503545,\n",
      "       0.00370827, 0.00422187, 0.07786341, 0.00472565, 0.00417242,\n",
      "       0.00861807, 0.00453959, 0.06634803, 0.00337915, 0.00334401,\n",
      "       0.00443997, 0.05026078, 0.09482498, 0.00444617, 0.00566401,\n",
      "       0.00911083, 0.09403038, 0.00487385, 0.07332759, 0.00674448]), 'std_fit_time': array([0.01445728, 0.00839835, 0.00192769, 0.0012801 , 0.00173559,\n",
      "       0.00112709, 0.00121982, 0.03726301, 0.00107347, 0.00075897,\n",
      "       0.00279275, 0.00180314, 0.03313011, 0.00116888, 0.0010102 ,\n",
      "       0.00232399, 0.0344789 , 0.05175786, 0.00206977, 0.00331676,\n",
      "       0.00359895, 0.04650086, 0.0026943 , 0.03524236, 0.00585147]), 'mean_score_time': array([0.00350161, 0.00458694, 0.00172844, 0.00189042, 0.00184622,\n",
      "       0.00171046, 0.00174422, 0.00179739, 0.00160174, 0.00214081,\n",
      "       0.00226598, 0.0015985 , 0.00282378, 0.00156655, 0.00158267,\n",
      "       0.00191669, 0.00352502, 0.00215826, 0.00189681, 0.00157442,\n",
      "       0.00199647, 0.00337353, 0.0024044 , 0.00251799, 0.00165091]), 'std_score_time': array([2.43698177e-03, 2.48182904e-03, 5.09980852e-05, 1.65751984e-04,\n",
      "       1.22018762e-04, 8.04350086e-05, 7.94284474e-05, 6.25437692e-05,\n",
      "       5.14914367e-05, 6.27165615e-04, 1.20048074e-03, 5.52525682e-05,\n",
      "       1.33245838e-03, 4.91791361e-05, 4.10704359e-05, 6.92674546e-04,\n",
      "       1.70618366e-03, 8.93938406e-04, 4.17306850e-04, 6.27229575e-05,\n",
      "       7.44129791e-04, 2.06317896e-03, 1.52022953e-03, 1.51029698e-03,\n",
      "       8.45755893e-05]), 'param_warm_start': masked_array(data=[True, True, True, True, True, True, False, False, True,\n",
      "                   True, True, False, False, True, True, False, False,\n",
      "                   False, True, False, False, True, False, True, True],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_tol': masked_array(data=[0.1, 10, 10, 0.1, 0.1, 0.01, 0.1, 0.01, 10, 1, 0.001,\n",
      "                   0.001, 0.01, 1, 0.1, 10, 0.0001, 0.1, 1, 1, 0.0001,\n",
      "                   0.1, 1, 0.0001, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_selection': masked_array(data=['random', 'random', 'cyclic', 'random', 'random',\n",
      "                   'random', 'random', 'cyclic', 'cyclic', 'random',\n",
      "                   'random', 'random', 'random', 'random', 'cyclic',\n",
      "                   'random', 'cyclic', 'cyclic', 'random', 'cyclic',\n",
      "                   'random', 'random', 'random', 'random', 'cyclic'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_fit_intercept': masked_array(data=[False, True, True, True, True, True, True, False,\n",
      "                   False, False, False, True, False, True, True, True,\n",
      "                   False, True, False, True, False, False, True, False,\n",
      "                   False],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_copy_X': masked_array(data=[True, True, False, True, True, True, False, True,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, True, False, False, False, True, True,\n",
      "                   True],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_alpha': masked_array(data=[0.01, 0.001, 0.1, 10, 1, 1, 0.01, 0.0001, 0.0001, 0.1,\n",
      "                   1, 1, 0.01, 0.1, 10, 0.001, 0.01, 0.0001, 10, 0.001,\n",
      "                   10, 0.0001, 1, 0.01, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'warm_start': True, 'tol': 0.1, 'selection': 'random', 'fit_intercept': False, 'copy_X': True, 'alpha': 0.01}, {'warm_start': True, 'tol': 10, 'selection': 'random', 'fit_intercept': True, 'copy_X': True, 'alpha': 0.001}, {'warm_start': True, 'tol': 10, 'selection': 'cyclic', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.1}, {'warm_start': True, 'tol': 0.1, 'selection': 'random', 'fit_intercept': True, 'copy_X': True, 'alpha': 10}, {'warm_start': True, 'tol': 0.1, 'selection': 'random', 'fit_intercept': True, 'copy_X': True, 'alpha': 1}, {'warm_start': True, 'tol': 0.01, 'selection': 'random', 'fit_intercept': True, 'copy_X': True, 'alpha': 1}, {'warm_start': False, 'tol': 0.1, 'selection': 'random', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.01}, {'warm_start': False, 'tol': 0.01, 'selection': 'cyclic', 'fit_intercept': False, 'copy_X': True, 'alpha': 0.0001}, {'warm_start': True, 'tol': 10, 'selection': 'cyclic', 'fit_intercept': False, 'copy_X': False, 'alpha': 0.0001}, {'warm_start': True, 'tol': 1, 'selection': 'random', 'fit_intercept': False, 'copy_X': False, 'alpha': 0.1}, {'warm_start': True, 'tol': 0.001, 'selection': 'random', 'fit_intercept': False, 'copy_X': False, 'alpha': 1}, {'warm_start': False, 'tol': 0.001, 'selection': 'random', 'fit_intercept': True, 'copy_X': False, 'alpha': 1}, {'warm_start': False, 'tol': 0.01, 'selection': 'random', 'fit_intercept': False, 'copy_X': False, 'alpha': 0.01}, {'warm_start': True, 'tol': 1, 'selection': 'random', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.1}, {'warm_start': True, 'tol': 0.1, 'selection': 'cyclic', 'fit_intercept': True, 'copy_X': False, 'alpha': 10}, {'warm_start': False, 'tol': 10, 'selection': 'random', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.001}, {'warm_start': False, 'tol': 0.0001, 'selection': 'cyclic', 'fit_intercept': False, 'copy_X': False, 'alpha': 0.01}, {'warm_start': False, 'tol': 0.1, 'selection': 'cyclic', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.0001}, {'warm_start': True, 'tol': 1, 'selection': 'random', 'fit_intercept': False, 'copy_X': True, 'alpha': 10}, {'warm_start': False, 'tol': 1, 'selection': 'cyclic', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.001}, {'warm_start': False, 'tol': 0.0001, 'selection': 'random', 'fit_intercept': False, 'copy_X': False, 'alpha': 10}, {'warm_start': True, 'tol': 0.1, 'selection': 'random', 'fit_intercept': False, 'copy_X': False, 'alpha': 0.0001}, {'warm_start': False, 'tol': 1, 'selection': 'random', 'fit_intercept': True, 'copy_X': True, 'alpha': 1}, {'warm_start': True, 'tol': 0.0001, 'selection': 'random', 'fit_intercept': False, 'copy_X': True, 'alpha': 0.01}, {'warm_start': True, 'tol': 10, 'selection': 'cyclic', 'fit_intercept': False, 'copy_X': True, 'alpha': 10}], 'split0_test_score': array([-1.11681677, -1.4155481 , -1.13139891, -1.17826425, -1.13720853,\n",
      "       -1.13664702, -1.11675819, -1.11672603, -3.18485849, -1.19891784,\n",
      "       -1.1364263 , -1.13654857, -1.1163756 , -1.12167292, -1.17826425,\n",
      "       -1.11879711, -1.11663372, -1.11668504, -3.30227499, -1.11698671,\n",
      "       -1.1788284 , -1.1164662 , -1.13947336, -1.11645705, -3.1498391 ]), 'split1_test_score': array([-1.3873449 , -1.64997465, -1.39015486, -1.42224662, -1.39656348,\n",
      "       -1.39656788, -1.38721799, -1.38808039, -3.03993263, -1.61376625,\n",
      "       -1.39669225, -1.39606894, -1.38575544, -1.38820228, -1.42225313,\n",
      "       -1.38697093, -1.38740078, -1.38911758, -1.66119215, -1.38747829,\n",
      "       -1.42288139, -1.38644708, -1.39775713, -1.38647513, -3.09071824]), 'split2_test_score': array([-1.059916  , -1.06026088, -1.06282571, -1.09900852, -1.06688456,\n",
      "       -1.06687108, -1.0600906 , -1.06003126, -2.11898523, -1.21060207,\n",
      "       -1.0668781 , -1.06686536, -1.05997459, -1.05974723, -1.09900852,\n",
      "       -1.05989751, -1.05997104, -1.06014283, -1.2226654 , -1.06017173,\n",
      "       -1.09899382, -1.0601086 , -1.34297682, -1.06003787, -2.16374414]), 'split3_test_score': array([-0.98913776, -0.99172765, -0.99371936, -1.04576643, -1.00675834,\n",
      "       -1.00675728, -1.00171273, -1.17003241, -1.88973282, -0.99704378,\n",
      "       -1.00677104, -1.00675712, -0.98484415, -0.99328486, -1.04576643,\n",
      "       -1.00208859, -1.03867396, -0.989085  , -1.66239501, -0.99276842,\n",
      "       -1.04570164, -1.10982265, -1.00638718, -0.99359914, -1.89831316]), 'split4_test_score': array([-0.93725407, -1.24322962, -0.93971947, -0.98963206, -0.9533683 ,\n",
      "       -0.95336879, -0.93741569, -0.93709213, -1.6560598 , -0.92343322,\n",
      "       -0.95338455, -0.95336843, -0.93726256, -0.94394538, -0.98963206,\n",
      "       -0.93898438, -0.93725475, -0.93709527, -1.02649246, -0.93725246,\n",
      "       -0.98944134, -0.93709151, -0.95358774, -0.9372554 , -1.651855  ]), 'mean_test_score': array([-1.0980939 , -1.27214818, -1.10356366, -1.14698358, -1.11215664,\n",
      "       -1.11204241, -1.10063904, -1.13439244, -2.37791379, -1.18875263,\n",
      "       -1.11203045, -1.11192168, -1.09684247, -1.10137053, -1.14698488,\n",
      "       -1.1013477 , -1.10798685, -1.09842514, -1.775004  , -1.09893152,\n",
      "       -1.14716932, -1.12198721, -1.16803645, -1.09876492, -2.39089393]), 'std_test_score': array([0.15698097, 0.23986853, 0.15714935, 0.1510326 , 0.15484634,\n",
      "       0.15483078, 0.15521583, 0.14859131, 0.61900994, 0.24015161,\n",
      "       0.154864  , 0.15464472, 0.15698462, 0.15548783, 0.15103498,\n",
      "       0.15480145, 0.15126543, 0.15766017, 0.80293687, 0.15652365,\n",
      "       0.15133679, 0.14705976, 0.17681081, 0.15603533, 0.6174404 ]), 'rank_test_score': array([ 2, 22,  9, 17, 14, 13,  6, 16, 24, 21, 12, 11,  1,  8, 18,  7, 10,\n",
      "        3, 23,  5, 19, 15, 20,  4, 25], dtype=int32)}\n",
      "Refit Time: 0.24970483779907227\n",
      "Scorer: make_scorer(mean_absolute_scaled_error, greater_is_better=False)\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: %s' % search.best_score_)\n",
    "print('Best Hyperparameters: %s' % search.best_params_)\n",
    "print('Best Model: %s' % search.best_estimator_)\n",
    "print('Best Index: %s' % search.best_index_)\n",
    "print('CV Results: %s' % search.cv_results_)\n",
    "print('Refit Time: %s' % search.refit_time_)\n",
    "print('Scorer: %s' % search.scorer_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
