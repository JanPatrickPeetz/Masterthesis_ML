{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for LASSO\n",
    "alpha = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "#max_iter = [500, 1000, 10000, 100000]\n",
    "selection = ['cyclic', 'random']\n",
    "fit_intercept = [True, False]\n",
    "tol = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "warm_start = [True, False]\n",
    "#positive = [True, False]\n",
    "#random_state = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "copy_X = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'alpha': alpha,\n",
    "               #'max_iter': max_iter,\n",
    "               'selection': selection,\n",
    "               'fit_intercept': fit_intercept,\n",
    "               'tol': tol,\n",
    "               'warm_start': warm_start,\n",
    "               #'positive': positive,\n",
    "               #'random_state': random_state,\n",
    "               'copy_X': copy_X}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define MASE Metric\n",
    "def mean_absolute_scaled_error(y_true, y_pred):\n",
    "    mase=0\n",
    "    # Define numerator as the forecast error\n",
    "    numerator = (np.abs(y_true - y_pred))\n",
    "\n",
    "    # Define denominator as the mean absolute error of the in-sample one-step naive forecast\n",
    "    y_true_ohne_1 = y_true[1:].reset_index(drop=True)\n",
    "    y_true_ohne_ende = y_true[:-1].reset_index(drop=True)\n",
    "    denominator = np.mean(np.abs(y_true_ohne_1 - y_true_ohne_ende))\n",
    "\n",
    "    mase = np.mean(np.abs(numerator / denominator))\n",
    "\n",
    "    return mase\n",
    "\n",
    "scorer_mase= make_scorer(mean_absolute_scaled_error, greater_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_parquet('/Users/paddy/Documents/GitHub/Masterthesis_ML/data/03_30min_dataset.parquet')\n",
    "\n",
    "# Convert the date column to datetime\n",
    "data['date'] = pd.to_datetime(data['date']) #,format='%d/%m/%y %H:%M:%S').dt.strftime('%Y-%m-%d %H:%M:%S') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering\n",
    "# Create a new column for the time\n",
    "data['time'] = [x for x in range(0, len(data))]\n",
    "\n",
    "data['hour_of_day'] = data['date'].dt.hour\n",
    "data['day_of_week'] = data['date'].dt.dayofweek\n",
    "data['day_of_month'] = data['date'].dt.day\n",
    "data['month_of_year'] = data['date'].dt.month\n",
    "data['year'] = data['date'].dt.year\n",
    "\n",
    "# make a weekend column\n",
    "data['weekend'] = 0\n",
    "data.loc[data['day_of_week'] == 5, 'weekend'] = 1\n",
    "data.loc[data['day_of_week'] == 6, 'weekend'] = 1\n",
    "\n",
    "#make a monday column\n",
    "data['monday'] = 0\n",
    "data.loc[data['day_of_week'] == 0, 'monday'] = 1\n",
    "\n",
    "#make a tuesday column\n",
    "data['tuesday'] = 0\n",
    "data.loc[data['day_of_week'] == 1, 'tuesday'] = 1\n",
    "\n",
    "#make a wednesday column\n",
    "data['wednesday'] = 0\n",
    "data.loc[data['day_of_week'] == 2, 'wednesday'] = 1\n",
    "\n",
    "#make a thursday column\n",
    "data['thursday'] = 0\n",
    "data.loc[data['day_of_week'] == 3, 'thursday'] = 1\n",
    "\n",
    "#make a friday column\n",
    "data['friday'] = 0\n",
    "data.loc[data['day_of_week'] == 4, 'friday'] = 1\n",
    "\n",
    "#make a saturday column\n",
    "data['saturday'] = 0\n",
    "data.loc[data['day_of_week'] == 5, 'saturday'] = 1\n",
    "\n",
    "#make a sunday column\n",
    "data['sunday'] = 0\n",
    "data.loc[data['day_of_week'] == 6, 'sunday'] = 1\n",
    "\n",
    "\n",
    "# Drop the first three rows\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "# Define the feature columns and the target column\n",
    "feature_cols = ['time', 'hour_of_day', 'day_of_week', 'day_of_month', 'month_of_year', 'year', 'weekend', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "target_col = 'y'\n",
    "\n",
    "# Drop nan values\n",
    "data = data.dropna()\n",
    "\n",
    "# Rename column count to y\n",
    "data = data.rename(columns={'count': 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set y to the last column\n",
    "cols = list(data.columns.values) #Make a list of all of the columns in the df\n",
    "cols.pop(cols.index('y')) #Remove y from list\n",
    "data = data[cols+['y']] #Create new dataframe with columns in the order you want\n",
    "\n",
    "# drop the date column\n",
    "train_data = np.delete(data, 0, 1) \n",
    "\n",
    "# Split the data into X and y\n",
    "X_train, y_train = train_data[:, :-1], train_data[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgl: https://lightrun.com/answers/scikit-learn-scikit-learn-grid_search-feeding-parameters-to-scorer-functions\n",
    "\n",
    "# X and y to pandas dataframe\n",
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = pd.Series(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Cross Validation to 5 iterations\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = Lasso()\n",
    "\n",
    "search = RandomizedSearchCV(estimator = model, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 25, \n",
    "                               cv = tscv,\n",
    "                               refit=True, \n",
    "                               verbose=3, \n",
    "                               random_state=42, \n",
    "                               n_jobs = -1, \n",
    "                               scoring=scorer_mase, #make_scorer(scorer_mase, greater_is_better=True), #'neg_root_mean_squared_error', #\n",
    "                               error_score=np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.197 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, copy_X=True, fit_intercept=True, selection=random, tol=10, warm_start=True;, score=-1.153 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, copy_X=True, fit_intercept=True, selection=random, tol=10, warm_start=True;, score=-1.318 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, copy_X=True, fit_intercept=True, selection=random, tol=10, warm_start=True;, score=-1.197 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, copy_X=True, fit_intercept=True, selection=random, tol=10, warm_start=True;, score=-1.068 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=cyclic, tol=10, warm_start=True;, score=-1.224 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=cyclic, tol=10, warm_start=True;, score=-1.324 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.490 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.001, copy_X=True, fit_intercept=True, selection=random, tol=10, warm_start=True;, score=-1.455 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.319 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.194 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=cyclic, tol=10, warm_start=True;, score=-1.198 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=cyclic, tol=10, warm_start=True;, score=-1.148 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=cyclic, tol=10, warm_start=True;, score=-1.073 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.298 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.066 total time=   0.2s\n",
      "[CV 2/5] END alpha=10, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.381 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.276 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.240 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.156 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.223 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.335 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.208 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.165 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.01, warm_start=True;, score=-1.221 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.089 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.01, warm_start=True;, score=-1.335 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.01, warm_start=True;, score=-1.208 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.01, warm_start=True;, score=-1.165 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.01, warm_start=True;, score=-1.089 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, copy_X=False, fit_intercept=True, selection=random, tol=0.1, warm_start=False;, score=-1.197 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, copy_X=False, fit_intercept=True, selection=random, tol=0.1, warm_start=False;, score=-1.318 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, copy_X=False, fit_intercept=True, selection=random, tol=0.1, warm_start=False;, score=-1.194 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, copy_X=False, fit_intercept=True, selection=random, tol=0.1, warm_start=False;, score=-1.140 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, copy_X=False, fit_intercept=True, selection=random, tol=0.1, warm_start=False;, score=-1.066 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-3.119 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, copy_X=True, fit_intercept=False, selection=cyclic, tol=0.01, warm_start=False;, score=-1.197 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-2.752 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-2.066 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-2.263 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-1.792 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, copy_X=False, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.200 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, copy_X=True, fit_intercept=False, selection=cyclic, tol=0.01, warm_start=False;, score=-1.319 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.1, copy_X=False, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.502 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, copy_X=False, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.278 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.864e+04, tolerance: 4.004e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+05, tolerance: 8.221e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.964e+05, tolerance: 1.206e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, copy_X=False, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.285 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=False, fit_intercept=False, selection=random, tol=0.001, warm_start=True;, score=-1.223 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, copy_X=False, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.249 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=False, fit_intercept=False, selection=random, tol=0.001, warm_start=True;, score=-1.335 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=False, fit_intercept=False, selection=random, tol=0.001, warm_start=True;, score=-1.208 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, copy_X=True, fit_intercept=False, selection=cyclic, tol=0.01, warm_start=False;, score=-1.195 total time=   0.2s\n",
      "[CV 2/5] END alpha=1, copy_X=False, fit_intercept=True, selection=random, tol=0.001, warm_start=False;, score=-1.335 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=False, fit_intercept=False, selection=random, tol=0.001, warm_start=True;, score=-1.089 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=False, fit_intercept=True, selection=random, tol=0.001, warm_start=False;, score=-1.224 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=False, fit_intercept=True, selection=random, tol=0.001, warm_start=False;, score=-1.165 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=False, fit_intercept=False, selection=random, tol=0.001, warm_start=True;, score=-1.165 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=False, fit_intercept=True, selection=random, tol=0.001, warm_start=False;, score=-1.208 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=False, fit_intercept=True, selection=random, tol=0.001, warm_start=False;, score=-1.089 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=random, tol=0.01, warm_start=False;, score=-1.196 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=random, tol=1, warm_start=True;, score=-1.320 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=random, tol=1, warm_start=True;, score=-1.463 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=random, tol=1, warm_start=True;, score=-1.153 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=True;, score=-1.298 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=True;, score=-1.381 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=True;, score=-1.276 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=random, tol=0.01, warm_start=False;, score=-1.318 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=random, tol=1, warm_start=True;, score=-1.071 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=True;, score=-1.240 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=True;, score=-1.156 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=random, tol=10, warm_start=False;, score=-1.218 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=random, tol=10, warm_start=False;, score=-1.323 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=random, tol=10, warm_start=False;, score=-1.145 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, copy_X=True, fit_intercept=False, selection=cyclic, tol=0.01, warm_start=False;, score=-1.323 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=random, tol=10, warm_start=False;, score=-1.463 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=random, tol=10, warm_start=False;, score=-1.068 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.618e+05, tolerance: 1.605e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.309e+05, tolerance: 2.054e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.780e+04, tolerance: 1.750e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=random, tol=0.01, warm_start=False;, score=-1.194 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=cyclic, tol=0.0001, warm_start=False;, score=-1.197 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=random, tol=0.01, warm_start=False;, score=-1.066 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=random, tol=1, warm_start=True;, score=-1.202 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=True, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.798 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=cyclic, tol=1, warm_start=False;, score=-1.318 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, copy_X=True, fit_intercept=False, selection=cyclic, tol=0.01, warm_start=False;, score=-1.066 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=cyclic, tol=0.0001, warm_start=False;, score=-1.318 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=True, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.167 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=cyclic, tol=0.0001, warm_start=False;, score=-1.066 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=cyclic, tol=1, warm_start=False;, score=-1.195 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=True, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.372 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=False, fit_intercept=False, selection=random, tol=0.0001, warm_start=False;, score=-1.298 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=cyclic, tol=1, warm_start=False;, score=-1.197 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=cyclic, tol=1, warm_start=False;, score=-1.143 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=False, fit_intercept=False, selection=random, tol=0.0001, warm_start=False;, score=-1.382 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=False, fit_intercept=False, selection=random, tol=0.0001, warm_start=False;, score=-1.276 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=cyclic, tol=1, warm_start=False;, score=-1.066 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=False, fit_intercept=False, selection=random, tol=0.0001, warm_start=False;, score=-1.156 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=False, fit_intercept=False, selection=random, tol=0.0001, warm_start=False;, score=-1.240 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=1, warm_start=False;, score=-1.208 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=random, tol=0.01, warm_start=False;, score=-1.128 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=cyclic, tol=0.0001, warm_start=False;, score=-1.194 total time=   0.1s\n",
      "[CV 4/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=1, warm_start=False;, score=-1.172 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=False;, score=-1.197 total time=   0.1s\n",
      "[CV 5/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=1, warm_start=False;, score=-1.089 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.865e+04, tolerance: 4.004e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.848e+04, tolerance: 4.004e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+05, tolerance: 8.221e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+05, tolerance: 3.556e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.614e+05, tolerance: 7.020e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.958e+05, tolerance: 1.206e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.614e+05, tolerance: 1.605e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.196 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.0001, warm_start=True;, score=-1.197 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.0001, warm_start=True;, score=-1.318 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0001, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=False;, score=-1.320 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=False;, score=-1.138 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.0001, warm_start=True;, score=-1.194 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=cyclic, tol=0.0001, warm_start=False;, score=-1.160 total time=   0.2s\n",
      "[CV 1/5] END alpha=10, copy_X=True, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-3.093 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=True, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-2.798 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=True, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-2.357 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=True, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-2.074 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=True, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-1.786 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.0001, warm_start=True;, score=-1.066 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.131 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.0001, warm_start=True;, score=-1.125 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.319 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=False;, score=-1.195 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.618e+05, tolerance: 1.605e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.323e+05, tolerance: 1.605e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+05, tolerance: 8.221e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.964e+05, tolerance: 5.239e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.963e+05, tolerance: 1.206e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.080e+05, tolerance: 9.040e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.309e+05, tolerance: 2.054e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.195 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=False;, score=-1.066 total time=   0.3s\n",
      "[CV 1/5] END alpha=10, copy_X=True, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-3.051 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=True, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.384 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.066 total time=   0.3s\n",
      "[CV 1/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=1, warm_start=False;, score=-1.467 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=1, warm_start=False;, score=-1.335 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Lasso(), n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                  10],\n",
       "                                        &#x27;copy_X&#x27;: [True, False],\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;selection&#x27;: [&#x27;cyclic&#x27;, &#x27;random&#x27;],\n",
       "                                        &#x27;tol&#x27;: [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                10],\n",
       "                                        &#x27;warm_start&#x27;: [True, False]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(mean_absolute_scaled_error, greater_is_better=False),\n",
       "                   verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Lasso(), n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                  10],\n",
       "                                        &#x27;copy_X&#x27;: [True, False],\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;selection&#x27;: [&#x27;cyclic&#x27;, &#x27;random&#x27;],\n",
       "                                        &#x27;tol&#x27;: [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                10],\n",
       "                                        &#x27;warm_start&#x27;: [True, False]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(mean_absolute_scaled_error, greater_is_better=False),\n",
       "                   verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Lasso(), n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={'alpha': [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                  10],\n",
       "                                        'copy_X': [True, False],\n",
       "                                        'fit_intercept': [True, False],\n",
       "                                        'selection': ['cyclic', 'random'],\n",
       "                                        'tol': [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                10],\n",
       "                                        'warm_start': [True, False]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(mean_absolute_scaled_error, greater_is_better=False),\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the random search model\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -1.1800154766869375\n",
      "Best Hyperparameters: {'warm_start': True, 'tol': 0.0001, 'selection': 'random', 'fit_intercept': False, 'copy_X': True, 'alpha': 0.01}\n",
      "Best Model: Lasso(alpha=0.01, fit_intercept=False, selection='random', warm_start=True)\n",
      "Best Index: 23\n",
      "CV Results: {'mean_fit_time': array([0.12586174, 0.00692544, 0.00631819, 0.006319  , 0.00627899,\n",
      "       0.00620737, 0.00788684, 0.20902634, 0.00855598, 0.00947537,\n",
      "       0.01753173, 0.01098394, 0.09904566, 0.00850029, 0.0075129 ,\n",
      "       0.00797987, 0.08633814, 0.21887779, 0.00726595, 0.01173487,\n",
      "       0.01351523, 0.22546587, 0.0099998 , 0.13067398, 0.00928621]), 'std_fit_time': array([0.05109531, 0.00251248, 0.00247577, 0.00220247, 0.00225969,\n",
      "       0.00222643, 0.00291912, 0.127421  , 0.00491472, 0.00404123,\n",
      "       0.00903823, 0.00544423, 0.05027675, 0.00525053, 0.00326024,\n",
      "       0.00439734, 0.06491659, 0.09934061, 0.00331167, 0.00911425,\n",
      "       0.00688512, 0.09132941, 0.0066566 , 0.05760919, 0.0052464 ]), 'mean_score_time': array([0.0041172 , 0.00515628, 0.00335779, 0.00277023, 0.0025146 ,\n",
      "       0.00246334, 0.00256352, 0.00401545, 0.00344906, 0.00306063,\n",
      "       0.00503068, 0.00575004, 0.00361533, 0.00280814, 0.00266485,\n",
      "       0.00518003, 0.00423098, 0.00354481, 0.0040936 , 0.00427504,\n",
      "       0.00250525, 0.002772  , 0.00231638, 0.00432973, 0.00263433]), 'std_score_time': array([1.74229252e-03, 4.37486520e-03, 1.45102391e-03, 1.34494234e-04,\n",
      "       9.29559765e-05, 7.82592779e-05, 5.55824022e-05, 1.79999401e-03,\n",
      "       2.19318263e-03, 1.13535463e-03, 1.89506186e-03, 4.32012475e-03,\n",
      "       1.25342884e-03, 8.81146976e-04, 4.72446382e-04, 3.71626480e-03,\n",
      "       2.09409056e-03, 1.79495544e-03, 2.98011545e-03, 2.04677206e-03,\n",
      "       1.81035760e-04, 6.57712100e-04, 2.40045982e-04, 2.81064701e-03,\n",
      "       4.73594690e-04]), 'param_warm_start': masked_array(data=[True, True, True, True, True, True, False, False, True,\n",
      "                   True, True, False, False, True, True, False, False,\n",
      "                   False, True, False, False, True, False, True, True],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_tol': masked_array(data=[0.1, 10, 10, 0.1, 0.1, 0.01, 0.1, 0.01, 10, 1, 0.001,\n",
      "                   0.001, 0.01, 1, 0.1, 10, 0.0001, 0.1, 1, 1, 0.0001,\n",
      "                   0.1, 1, 0.0001, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_selection': masked_array(data=['random', 'random', 'cyclic', 'random', 'random',\n",
      "                   'random', 'random', 'cyclic', 'cyclic', 'random',\n",
      "                   'random', 'random', 'random', 'random', 'cyclic',\n",
      "                   'random', 'cyclic', 'cyclic', 'random', 'cyclic',\n",
      "                   'random', 'random', 'random', 'random', 'cyclic'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_fit_intercept': masked_array(data=[False, True, True, True, True, True, True, False,\n",
      "                   False, False, False, True, False, True, True, True,\n",
      "                   False, True, False, True, False, False, True, False,\n",
      "                   False],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_copy_X': masked_array(data=[True, True, False, True, True, True, False, True,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, True, False, False, False, True, True,\n",
      "                   True],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_alpha': masked_array(data=[0.01, 0.001, 0.1, 10, 1, 1, 0.01, 0.0001, 0.0001, 0.1,\n",
      "                   1, 1, 0.01, 0.1, 10, 0.001, 0.01, 0.0001, 10, 0.001,\n",
      "                   10, 0.0001, 1, 0.01, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'warm_start': True, 'tol': 0.1, 'selection': 'random', 'fit_intercept': False, 'copy_X': True, 'alpha': 0.01}, {'warm_start': True, 'tol': 10, 'selection': 'random', 'fit_intercept': True, 'copy_X': True, 'alpha': 0.001}, {'warm_start': True, 'tol': 10, 'selection': 'cyclic', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.1}, {'warm_start': True, 'tol': 0.1, 'selection': 'random', 'fit_intercept': True, 'copy_X': True, 'alpha': 10}, {'warm_start': True, 'tol': 0.1, 'selection': 'random', 'fit_intercept': True, 'copy_X': True, 'alpha': 1}, {'warm_start': True, 'tol': 0.01, 'selection': 'random', 'fit_intercept': True, 'copy_X': True, 'alpha': 1}, {'warm_start': False, 'tol': 0.1, 'selection': 'random', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.01}, {'warm_start': False, 'tol': 0.01, 'selection': 'cyclic', 'fit_intercept': False, 'copy_X': True, 'alpha': 0.0001}, {'warm_start': True, 'tol': 10, 'selection': 'cyclic', 'fit_intercept': False, 'copy_X': False, 'alpha': 0.0001}, {'warm_start': True, 'tol': 1, 'selection': 'random', 'fit_intercept': False, 'copy_X': False, 'alpha': 0.1}, {'warm_start': True, 'tol': 0.001, 'selection': 'random', 'fit_intercept': False, 'copy_X': False, 'alpha': 1}, {'warm_start': False, 'tol': 0.001, 'selection': 'random', 'fit_intercept': True, 'copy_X': False, 'alpha': 1}, {'warm_start': False, 'tol': 0.01, 'selection': 'random', 'fit_intercept': False, 'copy_X': False, 'alpha': 0.01}, {'warm_start': True, 'tol': 1, 'selection': 'random', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.1}, {'warm_start': True, 'tol': 0.1, 'selection': 'cyclic', 'fit_intercept': True, 'copy_X': False, 'alpha': 10}, {'warm_start': False, 'tol': 10, 'selection': 'random', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.001}, {'warm_start': False, 'tol': 0.0001, 'selection': 'cyclic', 'fit_intercept': False, 'copy_X': False, 'alpha': 0.01}, {'warm_start': False, 'tol': 0.1, 'selection': 'cyclic', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.0001}, {'warm_start': True, 'tol': 1, 'selection': 'random', 'fit_intercept': False, 'copy_X': True, 'alpha': 10}, {'warm_start': False, 'tol': 1, 'selection': 'cyclic', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.001}, {'warm_start': False, 'tol': 0.0001, 'selection': 'random', 'fit_intercept': False, 'copy_X': False, 'alpha': 10}, {'warm_start': True, 'tol': 0.1, 'selection': 'random', 'fit_intercept': False, 'copy_X': False, 'alpha': 0.0001}, {'warm_start': False, 'tol': 1, 'selection': 'random', 'fit_intercept': True, 'copy_X': True, 'alpha': 1}, {'warm_start': True, 'tol': 0.0001, 'selection': 'random', 'fit_intercept': False, 'copy_X': True, 'alpha': 0.01}, {'warm_start': True, 'tol': 10, 'selection': 'cyclic', 'fit_intercept': False, 'copy_X': True, 'alpha': 10}], 'split0_test_score': array([-1.19653987, -1.45488794, -1.22435799, -1.29809362, -1.22313335,\n",
      "       -1.22108201, -1.19670056, -1.19683507, -3.1193773 , -1.20024996,\n",
      "       -1.22332845, -1.22356301, -1.19625979, -1.20214975, -1.29809362,\n",
      "       -1.2178259 , -1.19676812, -1.19661196, -3.05106146, -1.19729503,\n",
      "       -1.29848311, -1.19643943, -1.46737952, -1.19659285, -3.09257117]), 'split1_test_score': array([-1.31881227, -1.31799475, -1.32396493, -1.38134928, -1.33491105,\n",
      "       -1.33489876, -1.31827796, -1.31897288, -2.75185194, -1.502472  ,\n",
      "       -1.33510431, -1.33490056, -1.31799735, -1.31967011, -1.38134929,\n",
      "       -1.32338288, -1.31827235, -1.32001937, -1.38422939, -1.3183614 ,\n",
      "       -1.38164263, -1.31854183, -1.33490184, -1.31826358, -2.7980065 ]), 'split2_test_score': array([-1.19438815, -1.19683296, -1.19823469, -1.27566638, -1.20751992,\n",
      "       -1.20755313, -1.19422307, -1.19463178, -2.26288057, -1.27762074,\n",
      "       -1.20755219, -1.20751955, -1.19438206, -1.46334446, -1.27566636,\n",
      "       -1.46285945, -1.19442467, -1.19471858, -1.79756072, -1.19477304,\n",
      "       -1.2756531 , -1.19468364, -1.20752549, -1.19433788, -2.35707138]), 'split3_test_score': array([-1.48960537, -1.15286139, -1.14763802, -1.24004507, -1.1647352 ,\n",
      "       -1.16461258, -1.14023947, -1.32295456, -2.06555669, -1.28502628,\n",
      "       -1.16472423, -1.16475498, -1.12769276, -1.15298225, -1.24004507,\n",
      "       -1.14450924, -1.15992814, -1.13767074, -1.16651695, -1.14322508,\n",
      "       -1.23994592, -1.13080756, -1.17245392, -1.12480569, -2.07439659]), 'split4_test_score': array([-1.06607552, -1.06820969, -1.07277497, -1.15595706, -1.08925589,\n",
      "       -1.08925561, -1.06576193, -1.06562022, -1.79168882, -1.2494511 ,\n",
      "       -1.08926004, -1.08932089, -1.0660772 , -1.07088829, -1.15595706,\n",
      "       -1.06801639, -1.06607524, -1.06564677, -1.37249075, -1.06596493,\n",
      "       -1.15582598, -1.06562984, -1.08932142, -1.06607738, -1.78624953]), 'mean_test_score': array([-1.25308424, -1.23815734, -1.19339412, -1.27022228, -1.20391108,\n",
      "       -1.20348042, -1.1830406 , -1.2198029 , -2.39827106, -1.30296402,\n",
      "       -1.20399384, -1.2040118 , -1.18048183, -1.24180697, -1.27022228,\n",
      "       -1.24331877, -1.1870937 , -1.18293349, -1.75437185, -1.18392389,\n",
      "       -1.27031015, -1.18122046, -1.25431644, -1.18001548, -2.42165903]), 'std_test_score': array([0.14274255, 0.13506404, 0.08327488, 0.0736517 , 0.0802796 ,\n",
      "       0.08019376, 0.08268858, 0.0952978 , 0.47790901, 0.10409735,\n",
      "       0.08035221, 0.08027643, 0.08393781, 0.13697974, 0.0736517 ,\n",
      "       0.13838533, 0.080918  , 0.08357442, 0.67995312, 0.0823901 ,\n",
      "       0.07381842, 0.08387215, 0.13266809, 0.08440674, 0.47334311]), 'rank_test_score': array([17, 14,  8, 20, 10,  9,  5, 13, 24, 22, 11, 12,  2, 15, 19, 16,  7,\n",
      "        4, 23,  6, 21,  3, 18,  1, 25], dtype=int32)}\n",
      "Refit Time: 0.612861156463623\n",
      "Scorer: make_scorer(mean_absolute_scaled_error, greater_is_better=False)\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: %s' % search.best_score_)\n",
    "print('Best Hyperparameters: %s' % search.best_params_)\n",
    "print('Best Model: %s' % search.best_estimator_)\n",
    "print('Best Index: %s' % search.best_index_)\n",
    "print('CV Results: %s' % search.cv_results_)\n",
    "print('Refit Time: %s' % search.refit_time_)\n",
    "print('Scorer: %s' % search.scorer_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
