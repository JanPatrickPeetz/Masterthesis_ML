{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for linear regression\n",
    "\n",
    "# ridge parameters for random search\n",
    "fit_intercept = [True, False]\n",
    "copy_X = [True, False]\n",
    "alpha = [0.1, 0.5, 1, 2, 5, 10, 20, 50, 100]\n",
    "tol = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "solver = ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'fit_intercept': fit_intercept,\n",
    "                'copy_X': copy_X,\n",
    "                'alpha': alpha,\n",
    "                'tol': tol,\n",
    "                'solver': solver}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define MASE Metric\n",
    "def mean_absolute_scaled_error(y_true, y_pred):\n",
    "    mase=0\n",
    "    # Define numerator as the forecast error\n",
    "    numerator = (np.abs(y_true - y_pred))\n",
    "\n",
    "    # Define denominator as the mean absolute error of the in-sample one-step naive forecast\n",
    "    y_true_ohne_1 = y_true[1:].reset_index(drop=True)\n",
    "    y_true_ohne_ende = y_true[:-1].reset_index(drop=True)\n",
    "    denominator = np.mean(np.abs(y_true_ohne_1 - y_true_ohne_ende))\n",
    "\n",
    "    mase = np.mean(np.abs(numerator / denominator))\n",
    "\n",
    "    return mase\n",
    "\n",
    "scorer_mase= make_scorer(mean_absolute_scaled_error, greater_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_parquet('/Users/paddy/Documents/GitHub/Masterthesis_ML/data/03_30min_dataset.parquet')\n",
    "\n",
    "# Convert the date column to datetime\n",
    "data['date'] = pd.to_datetime(data['date']) #,format='%d/%m/%y %H:%M:%S').dt.strftime('%Y-%m-%d %H:%M:%S') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering\n",
    "# Create a new column for the time\n",
    "data['time'] = [x for x in range(0, len(data))]\n",
    "\n",
    "data['hour_of_day'] = data['date'].dt.hour\n",
    "data['day_of_week'] = data['date'].dt.dayofweek\n",
    "data['day_of_month'] = data['date'].dt.day\n",
    "data['month_of_year'] = data['date'].dt.month\n",
    "data['year'] = data['date'].dt.year\n",
    "\n",
    "# make a weekend column\n",
    "data['weekend'] = 0\n",
    "data.loc[data['day_of_week'] == 5, 'weekend'] = 1\n",
    "data.loc[data['day_of_week'] == 6, 'weekend'] = 1\n",
    "\n",
    "#make a monday column\n",
    "data['monday'] = 0\n",
    "data.loc[data['day_of_week'] == 0, 'monday'] = 1\n",
    "\n",
    "#make a tuesday column\n",
    "data['tuesday'] = 0\n",
    "data.loc[data['day_of_week'] == 1, 'tuesday'] = 1\n",
    "\n",
    "#make a wednesday column\n",
    "data['wednesday'] = 0\n",
    "data.loc[data['day_of_week'] == 2, 'wednesday'] = 1\n",
    "\n",
    "#make a thursday column\n",
    "data['thursday'] = 0\n",
    "data.loc[data['day_of_week'] == 3, 'thursday'] = 1\n",
    "\n",
    "#make a friday column\n",
    "data['friday'] = 0\n",
    "data.loc[data['day_of_week'] == 4, 'friday'] = 1\n",
    "\n",
    "#make a saturday column\n",
    "data['saturday'] = 0\n",
    "data.loc[data['day_of_week'] == 5, 'saturday'] = 1\n",
    "\n",
    "#make a sunday column\n",
    "data['sunday'] = 0\n",
    "data.loc[data['day_of_week'] == 6, 'sunday'] = 1\n",
    "\n",
    "\n",
    "# Drop the first three rows\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "# Define the feature columns and the target column\n",
    "feature_cols = ['time', 'hour_of_day', 'day_of_week', 'day_of_month', 'month_of_year', 'year', 'weekend', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "target_col = 'y'\n",
    "\n",
    "# Drop nan values\n",
    "data = data.dropna()\n",
    "\n",
    "# Rename column count to y\n",
    "data = data.rename(columns={'count': 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set y to the last column\n",
    "cols = list(data.columns.values) #Make a list of all of the columns in the df\n",
    "cols.pop(cols.index('y')) #Remove y from list\n",
    "data = data[cols+['y']] #Create new dataframe with columns in the order you want\n",
    "\n",
    "# drop the date column\n",
    "train_data = np.delete(data, 0, 1) \n",
    "\n",
    "# Split the data into X and y\n",
    "X_train, y_train = train_data[:, :-1], train_data[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgl: https://lightrun.com/answers/scikit-learn-scikit-learn-grid_search-feeding-parameters-to-scorer-functions\n",
    "\n",
    "# X and y to pandas dataframe\n",
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = pd.Series(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Cross Validation to 5 iterations\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = Ridge()\n",
    "\n",
    "search = RandomizedSearchCV(estimator = model, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 25, \n",
    "                               cv = tscv,\n",
    "                               refit=True, \n",
    "                               verbose=3, \n",
    "                               random_state=42, \n",
    "                               n_jobs = -1, \n",
    "                               scoring=scorer_mase, #make_scorer(scorer_mase, greater_is_better=True), #'neg_root_mean_squared_error', #\n",
    "                               error_score=np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=0.001;, score=-1.196 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=cholesky, tol=0.01;, score=-1.338 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=cholesky, tol=0.01;, score=-2.436 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=cholesky, tol=0.01;, score=-1.195 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=0.001;, score=-1.196 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=0.001;, score=-1.149 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=cholesky, tol=0.01;, score=-1.066 total time=   0.0s\n",
      "[CV 1/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=0.1;, score=-1.197 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=0.001;, score=-1.318 total time=   0.0s\n",
      "[CV 2/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=0.1;, score=-1.318 total time=   0.0s\n",
      "[CV 3/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=0.1;, score=-1.195 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=cholesky, tol=0.01;, score=-1.196 total time=   0.0s\n",
      "[CV 4/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=0.1;, score=-1.137 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=0.001;, score=-1.067 total time=   0.0s\n",
      "[CV 1/5] END alpha=50, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.445 total time=   0.0s\n",
      "[CV 5/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=0.1;, score=-1.066 total time=   0.0s\n",
      "[CV 2/5] END alpha=50, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.719 total time=   0.0s\n",
      "[CV 3/5] END alpha=50, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.462 total time=   0.0s\n",
      "[CV 4/5] END alpha=50, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-2.166 total time=   0.0s\n",
      "[CV 1/5] END alpha=20, copy_X=False, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.208 total time=   0.0s\n",
      "[CV 5/5] END alpha=50, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.396 total time=   0.0s\n",
      "[CV 2/5] END alpha=20, copy_X=False, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.328 total time=   0.0s\n",
      "[CV 3/5] END alpha=20, copy_X=False, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.201 total time=   0.0s\n",
      "[CV 4/5] END alpha=20, copy_X=False, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.164 total time=   0.0s\n",
      "[CV 5/5] END alpha=20, copy_X=False, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.086 total time=   0.0s\n",
      "[CV 1/5] END alpha=2, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.01;, score=-1.472 total time=   0.0s\n",
      "[CV 2/5] END alpha=2, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.01;, score=-1.561 total time=   0.0s\n",
      "[CV 3/5] END alpha=2, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.01;, score=-1.472 total time=   0.0s\n",
      "[CV 4/5] END alpha=2, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.01;, score=-1.442 total time=   0.0s\n",
      "[CV 5/5] END alpha=2, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.01;, score=-1.362 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=False, fit_intercept=True, solver=sag, tol=1;, score=-2.321 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=False, fit_intercept=True, solver=sag, tol=1;, score=-1.955 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=False, fit_intercept=True, solver=sag, tol=1;, score=-1.750 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=False, fit_intercept=True, solver=sag, tol=1;, score=-1.638 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=False, fit_intercept=True, solver=sag, tol=1;, score=-2.838 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=False, fit_intercept=False, solver=saga, tol=10;, score=-1.508 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=False, fit_intercept=False, solver=saga, tol=10;, score=-1.727 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=False, fit_intercept=False, solver=saga, tol=10;, score=-1.563 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=False, fit_intercept=False, solver=saga, tol=10;, score=-1.829 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=True, fit_intercept=False, solver=svd, tol=0.01;, score=-1.197 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=False, fit_intercept=False, solver=saga, tol=10;, score=-1.415 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=True, fit_intercept=False, solver=svd, tol=0.01;, score=-1.331 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=True, fit_intercept=False, solver=svd, tol=0.01;, score=-1.195 total time=   0.0s\n",
      "[CV 1/5] END alpha=100, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=1;, score=-2.041 total time=   0.0s\n",
      "[CV 2/5] END alpha=100, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=1;, score=-2.233 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=True, fit_intercept=False, solver=svd, tol=0.01;, score=-1.980 total time=   0.0s\n",
      "[CV 3/5] END alpha=100, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=1;, score=-2.024 total time=   0.0s\n",
      "[CV 5/5] END alpha=100, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=1;, score=-1.891 total time=   0.0s\n",
      "[CV 4/5] END alpha=100, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=1;, score=-1.846 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.5, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.485 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=True, fit_intercept=False, solver=svd, tol=0.01;, score=-1.066 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.5, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.720 total time=   0.0s\n",
      "[CV 1/5] END alpha=5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.208 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.5, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.455 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.5, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.474 total time=   0.0s\n",
      "[CV 2/5] END alpha=5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.328 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.5, copy_X=False, fit_intercept=True, solver=saga, tol=100;, score=-1.362 total time=   0.0s\n",
      "[CV 3/5] END alpha=5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.201 total time=   0.0s\n",
      "[CV 4/5] END alpha=5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.164 total time=   0.0s\n",
      "[CV 5/5] END alpha=5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.001;, score=-1.086 total time=   0.0s\n",
      "[CV 1/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sag, tol=10;, score=-1.477 total time=   0.0s\n",
      "[CV 2/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sag, tol=10;, score=-1.727 total time=   0.0s\n",
      "[CV 3/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sag, tol=10;, score=-1.477 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sag, tol=10;, score=-1.485 total time=   0.0s\n",
      "[CV 1/5] END alpha=100, copy_X=False, fit_intercept=True, solver=sag, tol=0.0001;, score=-1.200 total time=   0.3s\n",
      "[CV 1/5] END alpha=20, copy_X=True, fit_intercept=False, solver=saga, tol=10;, score=-1.532 total time=   0.0s\n",
      "[CV 5/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sag, tol=10;, score=-1.384 total time=   0.0s\n",
      "[CV 3/5] END alpha=20, copy_X=True, fit_intercept=False, solver=saga, tol=10;, score=-2.021 total time=   0.0s\n",
      "[CV 2/5] END alpha=20, copy_X=True, fit_intercept=False, solver=saga, tol=10;, score=-1.938 total time=   0.0s\n",
      "[CV 4/5] END alpha=20, copy_X=True, fit_intercept=False, solver=saga, tol=10;, score=-1.444 total time=   0.0s\n",
      "[CV 5/5] END alpha=20, copy_X=True, fit_intercept=False, solver=saga, tol=10;, score=-1.362 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=False, fit_intercept=False, solver=lsqr, tol=0.001;, score=-1.208 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=saga, tol=0.001;, score=-1.210 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=False, fit_intercept=False, solver=lsqr, tol=0.001;, score=-1.561 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=False, fit_intercept=False, solver=lsqr, tol=0.001;, score=-1.472 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=False, fit_intercept=False, solver=lsqr, tol=0.001;, score=-1.442 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=saga, tol=0.001;, score=-1.332 total time=   0.1s\n",
      "[CV 5/5] END alpha=1, copy_X=False, fit_intercept=False, solver=lsqr, tol=0.001;, score=-1.362 total time=   0.0s\n",
      "[CV 4/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=1;, score=-1.137 total time=   0.0s\n",
      "[CV 1/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=1;, score=-1.197 total time=   0.0s\n",
      "[CV 2/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=1;, score=-1.318 total time=   0.0s\n",
      "[CV 5/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=1;, score=-1.066 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.5, copy_X=True, fit_intercept=False, solver=auto, tol=100;, score=-1.196 total time=   0.0s\n",
      "[CV 3/5] END alpha=100, copy_X=False, fit_intercept=False, solver=svd, tol=1;, score=-1.195 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.5, copy_X=True, fit_intercept=False, solver=auto, tol=100;, score=-1.338 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.5, copy_X=True, fit_intercept=False, solver=auto, tol=100;, score=-1.195 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.5, copy_X=True, fit_intercept=False, solver=auto, tol=100;, score=-2.436 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.5, copy_X=True, fit_intercept=False, solver=auto, tol=100;, score=-1.066 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, copy_X=True, fit_intercept=False, solver=cholesky, tol=0.01;, score=-1.359 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, copy_X=True, fit_intercept=False, solver=cholesky, tol=0.01;, score=-1.196 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, copy_X=True, fit_intercept=False, solver=cholesky, tol=0.01;, score=-1.196 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, copy_X=True, fit_intercept=False, solver=cholesky, tol=0.01;, score=-3.108 total time=   0.0s\n",
      "[CV 1/5] END alpha=20, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.001;, score=-1.208 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, copy_X=True, fit_intercept=False, solver=cholesky, tol=0.01;, score=-1.066 total time=   0.0s\n",
      "[CV 2/5] END alpha=20, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.001;, score=-1.561 total time=   0.0s\n",
      "[CV 3/5] END alpha=20, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.001;, score=-1.472 total time=   0.0s\n",
      "[CV 5/5] END alpha=20, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.001;, score=-1.362 total time=   0.0s\n",
      "[CV 4/5] END alpha=20, copy_X=False, fit_intercept=False, solver=sparse_cg, tol=0.001;, score=-1.442 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.1;, score=-1.472 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.1;, score=-1.561 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.1;, score=-1.472 total time=   0.0s\n",
      "[CV 2/5] END alpha=100, copy_X=False, fit_intercept=True, solver=sag, tol=0.0001;, score=-1.321 total time=   0.7s\n",
      "[CV 4/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.1;, score=-1.442 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=lsqr, tol=0.1;, score=-1.362 total time=   0.0s\n",
      "[CV 3/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=0.0001;, score=-1.201 total time=   0.0s\n",
      "[CV 4/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=0.0001;, score=-1.164 total time=   0.0s\n",
      "[CV 1/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=0.0001;, score=-1.208 total time=   0.0s\n",
      "[CV 2/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=0.0001;, score=-1.328 total time=   0.0s\n",
      "[CV 5/5] END alpha=5, copy_X=True, fit_intercept=False, solver=sparse_cg, tol=0.0001;, score=-1.086 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=saga, tol=0.001;, score=-1.213 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=svd, tol=0.0001;, score=-1.196 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=svd, tol=0.0001;, score=-1.338 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=svd, tol=0.0001;, score=-1.195 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=svd, tol=0.0001;, score=-2.436 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=svd, tol=0.0001;, score=-1.066 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=100;, score=-1.463 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=100;, score=-1.554 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=100;, score=-1.476 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=100;, score=-1.445 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=False, fit_intercept=True, solver=sparse_cg, tol=100;, score=-1.362 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=saga, tol=0.001;, score=-1.179 total time=   0.5s\n",
      "[CV 3/5] END alpha=100, copy_X=False, fit_intercept=True, solver=sag, tol=0.0001;, score=-1.196 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=100, copy_X=False, fit_intercept=True, solver=sag, tol=0.0001;, score=-1.152 total time=   1.2s\n",
      "[CV 5/5] END alpha=0.5, copy_X=True, fit_intercept=True, solver=saga, tol=0.001;, score=-1.105 total time=   0.3s\n",
      "[CV 5/5] END alpha=100, copy_X=False, fit_intercept=True, solver=sag, tol=0.0001;, score=-1.076 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Ridge(), n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={&#x27;alpha&#x27;: [0.1, 0.5, 1, 2, 5, 10, 20, 50,\n",
       "                                                  100],\n",
       "                                        &#x27;copy_X&#x27;: [True, False],\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;solver&#x27;: [&#x27;auto&#x27;, &#x27;svd&#x27;, &#x27;cholesky&#x27;,\n",
       "                                                   &#x27;lsqr&#x27;, &#x27;sparse_cg&#x27;, &#x27;sag&#x27;,\n",
       "                                                   &#x27;saga&#x27;],\n",
       "                                        &#x27;tol&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10,\n",
       "                                                100]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(mean_absolute_scaled_error, greater_is_better=False),\n",
       "                   verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Ridge(), n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={&#x27;alpha&#x27;: [0.1, 0.5, 1, 2, 5, 10, 20, 50,\n",
       "                                                  100],\n",
       "                                        &#x27;copy_X&#x27;: [True, False],\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;solver&#x27;: [&#x27;auto&#x27;, &#x27;svd&#x27;, &#x27;cholesky&#x27;,\n",
       "                                                   &#x27;lsqr&#x27;, &#x27;sparse_cg&#x27;, &#x27;sag&#x27;,\n",
       "                                                   &#x27;saga&#x27;],\n",
       "                                        &#x27;tol&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10,\n",
       "                                                100]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(mean_absolute_scaled_error, greater_is_better=False),\n",
       "                   verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Ridge(), n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={'alpha': [0.1, 0.5, 1, 2, 5, 10, 20, 50,\n",
       "                                                  100],\n",
       "                                        'copy_X': [True, False],\n",
       "                                        'fit_intercept': [True, False],\n",
       "                                        'solver': ['auto', 'svd', 'cholesky',\n",
       "                                                   'lsqr', 'sparse_cg', 'sag',\n",
       "                                                   'saga'],\n",
       "                                        'tol': [0.0001, 0.001, 0.01, 0.1, 1, 10,\n",
       "                                                100]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(mean_absolute_scaled_error, greater_is_better=False),\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the random search model\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -1.1825137134613994\n",
      "Best Hyperparameters: {'tol': 0.1, 'solver': 'svd', 'fit_intercept': False, 'copy_X': False, 'alpha': 100}\n",
      "Best Model: Ridge(alpha=100, copy_X=False, fit_intercept=False, solver='svd', tol=0.1)\n",
      "Best Index: 2\n",
      "CV Results: {'mean_fit_time': array([0.01515703, 0.00927377, 0.01170921, 0.00718303, 0.00699377,\n",
      "       0.00598803, 0.89765983, 0.00956693, 0.00772138, 0.01145506,\n",
      "       0.00619588, 0.00933266, 0.00597091, 0.00654888, 0.00805073,\n",
      "       0.24725032, 0.01016512, 0.01260395, 0.00688014, 0.00984368,\n",
      "       0.01155901, 0.0068964 , 0.00918245, 0.00785742, 0.0064302 ]), 'std_fit_time': array([0.00712067, 0.0029089 , 0.00364689, 0.00238278, 0.00291762,\n",
      "       0.00205681, 0.36177174, 0.00443576, 0.00426863, 0.0090459 ,\n",
      "       0.00243387, 0.0036893 , 0.00220981, 0.00253577, 0.00250206,\n",
      "       0.15367655, 0.00437668, 0.00438634, 0.00216336, 0.00187809,\n",
      "       0.00746599, 0.00410833, 0.00398902, 0.00304306, 0.00144173]), 'mean_score_time': array([0.00558963, 0.00475888, 0.00409555, 0.00267072, 0.00358462,\n",
      "       0.00252986, 0.00252547, 0.00290289, 0.00275745, 0.00270743,\n",
      "       0.00240135, 0.00328193, 0.00277882, 0.00239325, 0.00262809,\n",
      "       0.00249252, 0.00331059, 0.00393338, 0.00264959, 0.0036314 ,\n",
      "       0.00429864, 0.00526075, 0.00327053, 0.00251184, 0.00291324]), 'std_score_time': array([1.74894661e-03, 1.60668962e-03, 1.76384677e-03, 7.99676529e-05,\n",
      "       1.97587965e-03, 9.76192928e-05, 9.09543100e-05, 9.43450962e-04,\n",
      "       6.11019172e-04, 5.81307902e-04, 7.12907433e-05, 1.39517956e-03,\n",
      "       9.49888528e-04, 1.24345015e-04, 4.01155877e-04, 1.61567924e-04,\n",
      "       1.08956427e-03, 1.37488056e-03, 6.88218385e-04, 1.61320867e-03,\n",
      "       1.90910564e-03, 3.79372247e-03, 1.74630391e-03, 1.59419620e-04,\n",
      "       1.04630144e-03]), 'param_tol': masked_array(data=[0.001, 0.01, 0.1, 100, 0.001, 0.01, 0.0001, 1, 10,\n",
      "                   0.01, 1, 100, 0.001, 10, 10, 0.001, 0.001, 1, 100,\n",
      "                   0.01, 0.001, 0.1, 0.0001, 0.0001, 100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_solver': masked_array(data=['sparse_cg', 'cholesky', 'svd', 'saga', 'lsqr',\n",
      "                   'sparse_cg', 'sag', 'sag', 'saga', 'svd', 'sparse_cg',\n",
      "                   'saga', 'lsqr', 'sag', 'saga', 'saga', 'lsqr', 'svd',\n",
      "                   'auto', 'cholesky', 'sparse_cg', 'lsqr', 'sparse_cg',\n",
      "                   'svd', 'sparse_cg'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_fit_intercept': masked_array(data=[True, True, False, True, True, False, True, True,\n",
      "                   False, False, False, True, True, False, False, True,\n",
      "                   False, False, False, False, False, True, False, True,\n",
      "                   True],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_copy_X': masked_array(data=[False, True, False, False, False, False, False, False,\n",
      "                   False, True, True, False, True, True, True, True,\n",
      "                   False, False, True, True, False, True, True, True,\n",
      "                   False],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_alpha': masked_array(data=[10, 0.5, 100, 50, 20, 2, 100, 1, 10, 1, 100, 0.5, 5, 5,\n",
      "                   20, 0.5, 1, 100, 0.5, 0.1, 20, 0.5, 5, 0.5, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'tol': 0.001, 'solver': 'sparse_cg', 'fit_intercept': True, 'copy_X': False, 'alpha': 10}, {'tol': 0.01, 'solver': 'cholesky', 'fit_intercept': True, 'copy_X': True, 'alpha': 0.5}, {'tol': 0.1, 'solver': 'svd', 'fit_intercept': False, 'copy_X': False, 'alpha': 100}, {'tol': 100, 'solver': 'saga', 'fit_intercept': True, 'copy_X': False, 'alpha': 50}, {'tol': 0.001, 'solver': 'lsqr', 'fit_intercept': True, 'copy_X': False, 'alpha': 20}, {'tol': 0.01, 'solver': 'sparse_cg', 'fit_intercept': False, 'copy_X': False, 'alpha': 2}, {'tol': 0.0001, 'solver': 'sag', 'fit_intercept': True, 'copy_X': False, 'alpha': 100}, {'tol': 1, 'solver': 'sag', 'fit_intercept': True, 'copy_X': False, 'alpha': 1}, {'tol': 10, 'solver': 'saga', 'fit_intercept': False, 'copy_X': False, 'alpha': 10}, {'tol': 0.01, 'solver': 'svd', 'fit_intercept': False, 'copy_X': True, 'alpha': 1}, {'tol': 1, 'solver': 'sparse_cg', 'fit_intercept': False, 'copy_X': True, 'alpha': 100}, {'tol': 100, 'solver': 'saga', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.5}, {'tol': 0.001, 'solver': 'lsqr', 'fit_intercept': True, 'copy_X': True, 'alpha': 5}, {'tol': 10, 'solver': 'sag', 'fit_intercept': False, 'copy_X': True, 'alpha': 5}, {'tol': 10, 'solver': 'saga', 'fit_intercept': False, 'copy_X': True, 'alpha': 20}, {'tol': 0.001, 'solver': 'saga', 'fit_intercept': True, 'copy_X': True, 'alpha': 0.5}, {'tol': 0.001, 'solver': 'lsqr', 'fit_intercept': False, 'copy_X': False, 'alpha': 1}, {'tol': 1, 'solver': 'svd', 'fit_intercept': False, 'copy_X': False, 'alpha': 100}, {'tol': 100, 'solver': 'auto', 'fit_intercept': False, 'copy_X': True, 'alpha': 0.5}, {'tol': 0.01, 'solver': 'cholesky', 'fit_intercept': False, 'copy_X': True, 'alpha': 0.1}, {'tol': 0.001, 'solver': 'sparse_cg', 'fit_intercept': False, 'copy_X': False, 'alpha': 20}, {'tol': 0.1, 'solver': 'lsqr', 'fit_intercept': True, 'copy_X': True, 'alpha': 0.5}, {'tol': 0.0001, 'solver': 'sparse_cg', 'fit_intercept': False, 'copy_X': True, 'alpha': 5}, {'tol': 0.0001, 'solver': 'svd', 'fit_intercept': True, 'copy_X': True, 'alpha': 0.5}, {'tol': 100, 'solver': 'sparse_cg', 'fit_intercept': True, 'copy_X': False, 'alpha': 10}], 'split0_test_score': array([-1.19612583, -1.1964329 , -1.19691789, -1.44467432, -1.20826063,\n",
      "       -1.4719201 , -1.19983473, -2.32118281, -1.50787451, -1.19652511,\n",
      "       -2.04123346, -1.48472016, -1.20824495, -1.47718644, -1.53228374,\n",
      "       -1.21044853, -1.20824699, -1.19691789, -1.1964329 , -1.19570838,\n",
      "       -1.20826684, -1.47248346, -1.20825117, -1.1964329 , -1.46295719]), 'split1_test_score': array([-1.31796295, -1.33841564, -1.31842481, -1.71870428, -1.32802424,\n",
      "       -1.56072517, -1.32135945, -1.95515601, -1.72656732, -1.3305335 ,\n",
      "       -2.23347751, -1.7198013 , -1.32802011, -1.72714168, -1.93751581,\n",
      "       -1.33227795, -1.56072517, -1.31842481, -1.33841558, -1.3593893 ,\n",
      "       -1.56072517, -1.5610905 , -1.32802865, -1.33841564, -1.55406772]), 'split2_test_score': array([-1.19579686, -1.19536325, -1.19456446, -1.46193288, -1.20091299,\n",
      "       -1.47212347, -1.19623221, -1.74989801, -1.56271846, -1.19516864,\n",
      "       -2.02426068, -1.47365636, -1.20090769, -1.47738715, -2.02055073,\n",
      "       -1.21301939, -1.47212347, -1.19456446, -1.19536325, -1.19567389,\n",
      "       -1.47212347, -1.47215082, -1.20091521, -1.19536325, -1.47627204]), 'split3_test_score': array([-1.14913086, -2.43584739, -1.13676679, -2.16612952, -1.1643466 ,\n",
      "       -1.44207776, -1.15193156, -1.63771277, -1.82921443, -1.98047358,\n",
      "       -1.84642854, -1.45482578, -1.1643426 , -1.4853027 , -1.44406937,\n",
      "       -1.17945046, -1.44207776, -1.13676679, -2.43597866, -3.10823891,\n",
      "       -1.44207776, -1.44206385, -1.16435628, -2.43584739, -1.44460822]), 'split4_test_score': array([-1.06701898, -1.06564419, -1.06589463, -1.39644586, -1.085763  ,\n",
      "       -1.36193051, -1.07640839, -2.83776803, -1.41549465, -1.06564558,\n",
      "       -1.89105389, -1.3620291 , -1.08575995, -1.38398351, -1.36208323,\n",
      "       -1.10523847, -1.36193051, -1.06589463, -1.06564431, -1.06564329,\n",
      "       -1.36193051, -1.3619501 , -1.08577542, -1.06564419, -1.36205729]), 'mean_test_score': array([-1.1852071 , -1.44634067, -1.18251371, -1.63757737, -1.19746149,\n",
      "       -1.4617554 , -1.18915327, -2.10034353, -1.60837387, -1.35366928,\n",
      "       -2.00729082, -1.49900654, -1.19745506, -1.51020029, -1.65930057,\n",
      "       -1.20808696, -1.40902078, -1.18251371, -1.44636694, -1.58493075,\n",
      "       -1.40902475, -1.46194775, -1.19746535, -1.44634067, -1.45999249]), 'std_test_score': array([0.0813946 , 0.502224  , 0.08308709, 0.28710832, 0.07841979,\n",
      "       0.06380917, 0.07967376, 0.43600082, 0.14975124, 0.32440508,\n",
      "       0.1356379 , 0.11858484, 0.07841914, 0.11470026, 0.26784372,\n",
      "       0.07328188, 0.11884153, 0.08308709, 0.50227571, 0.7673345 ,\n",
      "       0.11883482, 0.06393636, 0.07841666, 0.502224  , 0.06156613]), 'rank_test_score': array([ 3, 12,  1, 22,  6, 16,  4, 25, 21,  9, 24, 18,  5, 19, 23,  8, 10,\n",
      "        1, 14, 20, 11, 17,  7, 13, 15], dtype=int32)}\n",
      "Refit Time: 0.03156304359436035\n",
      "Scorer: make_scorer(mean_absolute_scaled_error, greater_is_better=False)\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: %s' % search.best_score_)\n",
    "print('Best Hyperparameters: %s' % search.best_params_)\n",
    "print('Best Model: %s' % search.best_estimator_)\n",
    "print('Best Index: %s' % search.best_index_)\n",
    "print('CV Results: %s' % search.cv_results_)\n",
    "print('Refit Time: %s' % search.refit_time_)\n",
    "print('Scorer: %s' % search.scorer_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
