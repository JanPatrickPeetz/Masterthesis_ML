{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for LASSO\n",
    "alpha = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "#max_iter = [500, 1000, 10000, 100000]\n",
    "selection = ['cyclic', 'random']\n",
    "fit_intercept = [True, False]\n",
    "tol = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "warm_start = [True, False]\n",
    "#positive = [True, False]\n",
    "#random_state = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "copy_X = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'alpha': alpha,\n",
    "               #'max_iter': max_iter,\n",
    "               'selection': selection,\n",
    "               'fit_intercept': fit_intercept,\n",
    "               'tol': tol,\n",
    "               'warm_start': warm_start,\n",
    "               #'positive': positive,\n",
    "               #'random_state': random_state,\n",
    "               'copy_X': copy_X}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define MASE Metric\n",
    "def mean_absolute_scaled_error(y_true, y_pred):\n",
    "    mase=0\n",
    "    # Define numerator as the forecast error\n",
    "    numerator = (np.abs(y_true - y_pred))\n",
    "\n",
    "    # Define denominator as the mean absolute error of the in-sample one-step naive forecast\n",
    "    y_true_ohne_1 = y_true[1:].reset_index(drop=True)\n",
    "    y_true_ohne_ende = y_true[:-1].reset_index(drop=True)\n",
    "    denominator = np.mean(np.abs(y_true_ohne_1 - y_true_ohne_ende))\n",
    "\n",
    "    mase = np.mean(np.abs(numerator / denominator))\n",
    "\n",
    "    return mase\n",
    "\n",
    "scorer_mase= make_scorer(mean_absolute_scaled_error, greater_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_parquet('/Users/paddy/Documents/GitHub/Masterthesis_ML/data/03_15min_dataset.parquet')\n",
    "\n",
    "# Convert the date column to datetime\n",
    "data['date'] = pd.to_datetime(data['date']) #,format='%d/%m/%y %H:%M:%S').dt.strftime('%Y-%m-%d %H:%M:%S') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       date  y  time  hour_of_day  day_of_week  day_of_month  \\\n",
      "0 2022-04-01 00:00:00+00:00  8     0            0            4             1   \n",
      "1 2022-04-01 00:15:00+00:00  1     1            0            4             1   \n",
      "2 2022-04-01 00:30:00+00:00  9     2            0            4             1   \n",
      "3 2022-04-01 00:45:00+00:00  8     3            0            4             1   \n",
      "4 2022-04-01 01:00:00+00:00  4     4            1            4             1   \n",
      "\n",
      "   month_of_year  year  weekend  monday  tuesday  wednesday  thursday  friday  \\\n",
      "0              4  2022        0       0        0          0         0       1   \n",
      "1              4  2022        0       0        0          0         0       1   \n",
      "2              4  2022        0       0        0          0         0       1   \n",
      "3              4  2022        0       0        0          0         0       1   \n",
      "4              4  2022        0       0        0          0         0       1   \n",
      "\n",
      "   saturday  sunday  \n",
      "0         0       0  \n",
      "1         0       0  \n",
      "2         0       0  \n",
      "3         0       0  \n",
      "4         0       0  \n"
     ]
    }
   ],
   "source": [
    "#Feature engineering\n",
    "# Create a new column for the time\n",
    "data['time'] = [x for x in range(0, len(data))]\n",
    "\n",
    "data['hour_of_day'] = data['date'].dt.hour\n",
    "data['day_of_week'] = data['date'].dt.dayofweek\n",
    "data['day_of_month'] = data['date'].dt.day\n",
    "data['month_of_year'] = data['date'].dt.month\n",
    "data['year'] = data['date'].dt.year\n",
    "\n",
    "# make a weekend column\n",
    "data['weekend'] = 0\n",
    "data.loc[data['day_of_week'] == 5, 'weekend'] = 1\n",
    "data.loc[data['day_of_week'] == 6, 'weekend'] = 1\n",
    "\n",
    "#make a monday column\n",
    "data['monday'] = 0\n",
    "data.loc[data['day_of_week'] == 0, 'monday'] = 1\n",
    "\n",
    "#make a tuesday column\n",
    "data['tuesday'] = 0\n",
    "data.loc[data['day_of_week'] == 1, 'tuesday'] = 1\n",
    "\n",
    "#make a wednesday column\n",
    "data['wednesday'] = 0\n",
    "data.loc[data['day_of_week'] == 2, 'wednesday'] = 1\n",
    "\n",
    "#make a thursday column\n",
    "data['thursday'] = 0\n",
    "data.loc[data['day_of_week'] == 3, 'thursday'] = 1\n",
    "\n",
    "#make a friday column\n",
    "data['friday'] = 0\n",
    "data.loc[data['day_of_week'] == 4, 'friday'] = 1\n",
    "\n",
    "#make a saturday column\n",
    "data['saturday'] = 0\n",
    "data.loc[data['day_of_week'] == 5, 'saturday'] = 1\n",
    "\n",
    "#make a sunday column\n",
    "data['sunday'] = 0\n",
    "data.loc[data['day_of_week'] == 6, 'sunday'] = 1\n",
    "\n",
    "\n",
    "# Drop the first three rows\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "# Define the feature columns and the target column\n",
    "feature_cols = ['time', 'hour_of_day', 'day_of_week', 'day_of_month', 'month_of_year', 'year', 'weekend', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "target_col = 'y'\n",
    "\n",
    "# Drop nan values\n",
    "data = data.dropna()\n",
    "\n",
    "# Rename column count to y\n",
    "data = data.rename(columns={'count': 'y'})\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 4 ... 1 0 0]\n",
      " [1 0 4 ... 1 0 0]\n",
      " [2 0 4 ... 1 0 0]\n",
      " ...\n",
      " [35037 23 4 ... 1 0 0]\n",
      " [35038 23 4 ... 1 0 0]\n",
      " [35039 23 4 ... 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Set y to the last column\n",
    "cols = list(data.columns.values) #Make a list of all of the columns in the df\n",
    "cols.pop(cols.index('y')) #Remove y from list\n",
    "data = data[cols+['y']] #Create new dataframe with columns in the order you want\n",
    "\n",
    "# drop the date column\n",
    "train_data = np.delete(data, 0, 1) \n",
    "\n",
    "# Split the data into X and y\n",
    "X_train, y_train = train_data[:, :-1], train_data[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgl: https://lightrun.com/answers/scikit-learn-scikit-learn-grid_search-feeding-parameters-to-scorer-functions\n",
    "\n",
    "# X and y to pandas dataframe\n",
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = pd.Series(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Cross Validation to 5 iterations\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = Lasso()\n",
    "\n",
    "# Instantiate RandomizedSearchCV object\n",
    "search = RandomizedSearchCV(estimator = model, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 25, \n",
    "                               cv = tscv,\n",
    "                               refit=True, \n",
    "                               verbose=3, \n",
    "                               random_state=42, \n",
    "                               n_jobs = -1, \n",
    "                               scoring=scorer_mase, #make_scorer(scorer_mase, greater_is_better=True), #'neg_root_mean_squared_error', #\n",
    "                               error_score=np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.001, copy_X=True, fit_intercept=True, selection=random, tol=10, warm_start=True;, score=-1.250 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, copy_X=True, fit_intercept=True, selection=random, tol=10, warm_start=True;, score=-1.390 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.175 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=cyclic, tol=10, warm_start=True;, score=-1.208 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, copy_X=True, fit_intercept=True, selection=random, tol=10, warm_start=True;, score=-1.445 total time=   0.0s[CV 5/5] END alpha=0.001, copy_X=True, fit_intercept=True, selection=random, tol=10, warm_start=True;, score=-1.386 total time=   0.0s\n",
      "\n",
      "[CV 4/5] END alpha=0.001, copy_X=True, fit_intercept=True, selection=random, tol=10, warm_start=True;, score=-1.191 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.257 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=cyclic, tol=10, warm_start=True;, score=-1.266 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.128 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.208 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=cyclic, tol=10, warm_start=True;, score=-1.186 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=cyclic, tol=10, warm_start=True;, score=-1.213 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.361 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=cyclic, tol=10, warm_start=True;, score=-1.140 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.396 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.378 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.175 total time=   0.3s\n",
      "[CV 4/5] END alpha=10, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.361 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.306 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.214 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.276 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.227 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.204 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.01, warm_start=True;, score=-1.214 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.1, warm_start=True;, score=-1.156 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.01, warm_start=True;, score=-1.276 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.01, warm_start=True;, score=-1.227 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.01, warm_start=True;, score=-1.204 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=0.01, warm_start=True;, score=-1.156 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, copy_X=False, fit_intercept=True, selection=random, tol=0.1, warm_start=False;, score=-1.175 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, copy_X=False, fit_intercept=True, selection=random, tol=0.1, warm_start=False;, score=-1.257 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, copy_X=False, fit_intercept=True, selection=random, tol=0.1, warm_start=False;, score=-1.207 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, copy_X=False, fit_intercept=True, selection=random, tol=0.1, warm_start=False;, score=-1.187 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, copy_X=False, fit_intercept=True, selection=random, tol=0.1, warm_start=False;, score=-1.128 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-2.819 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, copy_X=True, fit_intercept=False, selection=cyclic, tol=0.01, warm_start=False;, score=-1.175 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-2.462 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-2.161 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-2.027 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, copy_X=False, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.196 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-1.818 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.498e+04, tolerance: 2.215e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.831e+04, tolerance: 4.534e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, copy_X=False, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-2.154 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, copy_X=False, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.330 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, copy_X=False, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.178 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=False, fit_intercept=False, selection=random, tol=0.001, warm_start=True;, score=-1.214 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, copy_X=True, fit_intercept=False, selection=cyclic, tol=0.01, warm_start=False;, score=-1.258 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.1, copy_X=False, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.187 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=False, fit_intercept=False, selection=random, tol=0.001, warm_start=True;, score=-1.276 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=False, fit_intercept=False, selection=random, tol=0.001, warm_start=True;, score=-1.227 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=False, fit_intercept=True, selection=random, tol=0.001, warm_start=False;, score=-1.214 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=False, fit_intercept=False, selection=random, tol=0.001, warm_start=True;, score=-1.204 total time=   0.1s\n",
      "[CV 5/5] END alpha=1, copy_X=False, fit_intercept=False, selection=random, tol=0.001, warm_start=True;, score=-1.157 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=False, fit_intercept=True, selection=random, tol=0.001, warm_start=False;, score=-1.276 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=False, fit_intercept=True, selection=random, tol=0.001, warm_start=False;, score=-1.227 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=False, fit_intercept=True, selection=random, tol=0.001, warm_start=False;, score=-1.204 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=False, fit_intercept=True, selection=random, tol=0.001, warm_start=False;, score=-1.156 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, copy_X=True, fit_intercept=False, selection=cyclic, tol=0.01, warm_start=False;, score=-1.208 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=random, tol=0.01, warm_start=False;, score=-1.175 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=random, tol=1, warm_start=True;, score=-1.403 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=random, tol=1, warm_start=True;, score=-1.455 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e+05, tolerance: 6.631e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.707e+05, tolerance: 8.821e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=random, tol=1, warm_start=True;, score=-1.211 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=random, tol=1, warm_start=True;, score=-1.185 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=random, tol=0.01, warm_start=False;, score=-1.128 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, copy_X=True, fit_intercept=False, selection=cyclic, tol=0.01, warm_start=False;, score=-1.335 total time=   0.6s\n",
      "[CV 4/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=random, tol=0.01, warm_start=False;, score=-1.300 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.1, copy_X=False, fit_intercept=True, selection=random, tol=1, warm_start=True;, score=-1.139 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=True;, score=-1.361 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=random, tol=0.01, warm_start=False;, score=-1.208 total time=   0.2s\n",
      "[CV 2/5] END alpha=10, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=True;, score=-1.396 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=random, tol=0.01, warm_start=False;, score=-1.257 total time=   0.3s\n",
      "[CV 3/5] END alpha=10, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=True;, score=-1.378 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=True;, score=-1.361 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=True;, score=-1.306 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=random, tol=10, warm_start=False;, score=-1.178 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=random, tol=10, warm_start=False;, score=-1.448 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=random, tol=10, warm_start=False;, score=-1.229 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=random, tol=10, warm_start=False;, score=-1.189 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=random, tol=10, warm_start=False;, score=-1.134 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.156e+05, tolerance: 1.127e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, copy_X=True, fit_intercept=False, selection=cyclic, tol=0.01, warm_start=False;, score=-1.127 total time=   0.8s\n",
      "[CV 1/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=cyclic, tol=0.0001, warm_start=False;, score=-1.175 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=cyclic, tol=0.0001, warm_start=False;, score=-1.257 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=cyclic, tol=0.0001, warm_start=False;, score=-1.208 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=cyclic, tol=0.0001, warm_start=False;, score=-1.128 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.0001, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=False;, score=-1.175 total time=   0.1s\n",
      "[CV 1/5] END alpha=10, copy_X=True, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.245 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=True, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.496 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=True, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.422 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=True, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.608 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=True, fit_intercept=False, selection=random, tol=1, warm_start=True;, score=-1.268 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, copy_X=False, fit_intercept=False, selection=cyclic, tol=0.0001, warm_start=False;, score=-1.175 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=cyclic, tol=1, warm_start=False;, score=-1.176 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=cyclic, tol=1, warm_start=False;, score=-1.257 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=False;, score=-1.258 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=cyclic, tol=1, warm_start=False;, score=-1.208 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=cyclic, tol=1, warm_start=False;, score=-1.178 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, copy_X=False, fit_intercept=True, selection=cyclic, tol=1, warm_start=False;, score=-1.128 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=False, fit_intercept=False, selection=random, tol=0.0001, warm_start=False;, score=-1.361 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=False, fit_intercept=False, selection=random, tol=0.0001, warm_start=False;, score=-1.397 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=False, fit_intercept=False, selection=random, tol=0.0001, warm_start=False;, score=-1.378 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.834e+04, tolerance: 2.202e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.282e+05, tolerance: 3.221e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=10, copy_X=False, fit_intercept=False, selection=random, tol=0.0001, warm_start=False;, score=-1.361 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=False, fit_intercept=False, selection=random, tol=0.0001, warm_start=False;, score=-1.306 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=False;, score=-1.174 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=False;, score=-1.208 total time=   0.4s\n",
      "[CV 1/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=1, warm_start=False;, score=-1.211 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.175 total time=   0.1s\n",
      "[CV 2/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=1, warm_start=False;, score=-1.276 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=1, warm_start=False;, score=-1.450 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=1, warm_start=False;, score=-1.204 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.498e+04, tolerance: 2.215e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=1, copy_X=True, fit_intercept=True, selection=random, tol=1, warm_start=False;, score=-1.156 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, copy_X=False, fit_intercept=True, selection=cyclic, tol=0.1, warm_start=False;, score=-1.127 total time=   0.6s\n",
      "[CV 1/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.0001, warm_start=True;, score=-1.175 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.257 total time=   0.3s\n",
      "[CV 1/5] END alpha=10, copy_X=True, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-2.804 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.834e+04, tolerance: 4.534e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.715e+04, tolerance: 4.534e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.282e+05, tolerance: 6.631e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.0001, warm_start=True;, score=-1.257 total time=   0.2s\n",
      "[CV 2/5] END alpha=10, copy_X=True, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-2.506 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=True, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-2.249 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=True, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-2.043 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.0001, warm_start=True;, score=-1.208 total time=   0.3s\n",
      "[CV 5/5] END alpha=10, copy_X=True, fit_intercept=False, selection=cyclic, tol=10, warm_start=True;, score=-1.826 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.208 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.0001, warm_start=True;, score=-1.128 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.01, copy_X=True, fit_intercept=False, selection=random, tol=0.0001, warm_start=True;, score=-1.175 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.707e+05, tolerance: 8.821e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/paddy/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.156e+05, tolerance: 1.127e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.415 total time=   0.6s\n",
      "[CV 5/5] END alpha=0.0001, copy_X=False, fit_intercept=False, selection=random, tol=0.1, warm_start=True;, score=-1.127 total time=   0.7s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Lasso(), n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                  10],\n",
       "                                        &#x27;copy_X&#x27;: [True, False],\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;selection&#x27;: [&#x27;cyclic&#x27;, &#x27;random&#x27;],\n",
       "                                        &#x27;tol&#x27;: [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                10],\n",
       "                                        &#x27;warm_start&#x27;: [True, False]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(mean_absolute_scaled_error, greater_is_better=False),\n",
       "                   verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Lasso(), n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                  10],\n",
       "                                        &#x27;copy_X&#x27;: [True, False],\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;selection&#x27;: [&#x27;cyclic&#x27;, &#x27;random&#x27;],\n",
       "                                        &#x27;tol&#x27;: [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                10],\n",
       "                                        &#x27;warm_start&#x27;: [True, False]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(mean_absolute_scaled_error, greater_is_better=False),\n",
       "                   verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Lasso(), n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={'alpha': [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                  10],\n",
       "                                        'copy_X': [True, False],\n",
       "                                        'fit_intercept': [True, False],\n",
       "                                        'selection': ['cyclic', 'random'],\n",
       "                                        'tol': [0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                                10],\n",
       "                                        'warm_start': [True, False]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(mean_absolute_scaled_error, greater_is_better=False),\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the random search model\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -1.1884723020480603\n",
      "Best Hyperparameters: {'warm_start': True, 'tol': 0.1, 'selection': 'random', 'fit_intercept': False, 'copy_X': True, 'alpha': 0.01}\n",
      "Best Model: Lasso(alpha=0.01, fit_intercept=False, selection='random', tol=0.1,\n",
      "      warm_start=True)\n",
      "Best Index: 0\n",
      "CV Results: {'mean_fit_time': array([0.20230336, 0.01973467, 0.01286464, 0.01205797, 0.0120935 ,\n",
      "       0.01207685, 0.01598716, 0.44771676, 0.01251364, 0.01823215,\n",
      "       0.02822599, 0.01173768, 0.16104641, 0.01366487, 0.01165557,\n",
      "       0.01267858, 0.11152334, 0.34896798, 0.01869698, 0.01640182,\n",
      "       0.02750273, 0.45132518, 0.01600237, 0.2139596 , 0.01280265]), 'std_fit_time': array([0.03853148, 0.01297029, 0.00350412, 0.00468362, 0.00490226,\n",
      "       0.00509114, 0.00549363, 0.23849257, 0.00572655, 0.00998335,\n",
      "       0.0126503 , 0.00476974, 0.06230539, 0.00517585, 0.00462655,\n",
      "       0.00393931, 0.08431484, 0.17936416, 0.0085706 , 0.00406974,\n",
      "       0.0133887 , 0.20019422, 0.00761008, 0.06214634, 0.00434028]), 'mean_score_time': array([0.00509439, 0.00933695, 0.00609317, 0.00417519, 0.00461655,\n",
      "       0.0045536 , 0.00471683, 0.00771837, 0.00604305, 0.0098412 ,\n",
      "       0.0055028 , 0.00476122, 0.0060225 , 0.00640173, 0.00454435,\n",
      "       0.00464277, 0.00417476, 0.00574031, 0.00645576, 0.00530562,\n",
      "       0.0056778 , 0.00399437, 0.00613246, 0.00728307, 0.00648198]), 'std_score_time': array([0.00072544, 0.00475473, 0.00321646, 0.00011951, 0.00049416,\n",
      "       0.00029341, 0.00044108, 0.00437021, 0.00168559, 0.00249839,\n",
      "       0.00215443, 0.00105553, 0.00345831, 0.00287712, 0.00066542,\n",
      "       0.00060179, 0.00022018, 0.00232243, 0.00171386, 0.00209198,\n",
      "       0.00158473, 0.00025449, 0.00250651, 0.00275696, 0.00192225]), 'param_warm_start': masked_array(data=[True, True, True, True, True, True, False, False, True,\n",
      "                   True, True, False, False, True, True, False, False,\n",
      "                   False, True, False, False, True, False, True, True],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_tol': masked_array(data=[0.1, 10, 10, 0.1, 0.1, 0.01, 0.1, 0.01, 10, 1, 0.001,\n",
      "                   0.001, 0.01, 1, 0.1, 10, 0.0001, 0.1, 1, 1, 0.0001,\n",
      "                   0.1, 1, 0.0001, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_selection': masked_array(data=['random', 'random', 'cyclic', 'random', 'random',\n",
      "                   'random', 'random', 'cyclic', 'cyclic', 'random',\n",
      "                   'random', 'random', 'random', 'random', 'cyclic',\n",
      "                   'random', 'cyclic', 'cyclic', 'random', 'cyclic',\n",
      "                   'random', 'random', 'random', 'random', 'cyclic'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_fit_intercept': masked_array(data=[False, True, True, True, True, True, True, False,\n",
      "                   False, False, False, True, False, True, True, True,\n",
      "                   False, True, False, True, False, False, True, False,\n",
      "                   False],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_copy_X': masked_array(data=[True, True, False, True, True, True, False, True,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, True, False, False, False, True, True,\n",
      "                   True],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_alpha': masked_array(data=[0.01, 0.001, 0.1, 10, 1, 1, 0.01, 0.0001, 0.0001, 0.1,\n",
      "                   1, 1, 0.01, 0.1, 10, 0.001, 0.01, 0.0001, 10, 0.001,\n",
      "                   10, 0.0001, 1, 0.01, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'warm_start': True, 'tol': 0.1, 'selection': 'random', 'fit_intercept': False, 'copy_X': True, 'alpha': 0.01}, {'warm_start': True, 'tol': 10, 'selection': 'random', 'fit_intercept': True, 'copy_X': True, 'alpha': 0.001}, {'warm_start': True, 'tol': 10, 'selection': 'cyclic', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.1}, {'warm_start': True, 'tol': 0.1, 'selection': 'random', 'fit_intercept': True, 'copy_X': True, 'alpha': 10}, {'warm_start': True, 'tol': 0.1, 'selection': 'random', 'fit_intercept': True, 'copy_X': True, 'alpha': 1}, {'warm_start': True, 'tol': 0.01, 'selection': 'random', 'fit_intercept': True, 'copy_X': True, 'alpha': 1}, {'warm_start': False, 'tol': 0.1, 'selection': 'random', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.01}, {'warm_start': False, 'tol': 0.01, 'selection': 'cyclic', 'fit_intercept': False, 'copy_X': True, 'alpha': 0.0001}, {'warm_start': True, 'tol': 10, 'selection': 'cyclic', 'fit_intercept': False, 'copy_X': False, 'alpha': 0.0001}, {'warm_start': True, 'tol': 1, 'selection': 'random', 'fit_intercept': False, 'copy_X': False, 'alpha': 0.1}, {'warm_start': True, 'tol': 0.001, 'selection': 'random', 'fit_intercept': False, 'copy_X': False, 'alpha': 1}, {'warm_start': False, 'tol': 0.001, 'selection': 'random', 'fit_intercept': True, 'copy_X': False, 'alpha': 1}, {'warm_start': False, 'tol': 0.01, 'selection': 'random', 'fit_intercept': False, 'copy_X': False, 'alpha': 0.01}, {'warm_start': True, 'tol': 1, 'selection': 'random', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.1}, {'warm_start': True, 'tol': 0.1, 'selection': 'cyclic', 'fit_intercept': True, 'copy_X': False, 'alpha': 10}, {'warm_start': False, 'tol': 10, 'selection': 'random', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.001}, {'warm_start': False, 'tol': 0.0001, 'selection': 'cyclic', 'fit_intercept': False, 'copy_X': False, 'alpha': 0.01}, {'warm_start': False, 'tol': 0.1, 'selection': 'cyclic', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.0001}, {'warm_start': True, 'tol': 1, 'selection': 'random', 'fit_intercept': False, 'copy_X': True, 'alpha': 10}, {'warm_start': False, 'tol': 1, 'selection': 'cyclic', 'fit_intercept': True, 'copy_X': False, 'alpha': 0.001}, {'warm_start': False, 'tol': 0.0001, 'selection': 'random', 'fit_intercept': False, 'copy_X': False, 'alpha': 10}, {'warm_start': True, 'tol': 0.1, 'selection': 'random', 'fit_intercept': False, 'copy_X': False, 'alpha': 0.0001}, {'warm_start': False, 'tol': 1, 'selection': 'random', 'fit_intercept': True, 'copy_X': True, 'alpha': 1}, {'warm_start': True, 'tol': 0.0001, 'selection': 'random', 'fit_intercept': False, 'copy_X': True, 'alpha': 0.01}, {'warm_start': True, 'tol': 10, 'selection': 'cyclic', 'fit_intercept': False, 'copy_X': True, 'alpha': 10}], 'split0_test_score': array([-1.17510965, -1.39031094, -1.20781061, -1.3608806 , -1.21424803,\n",
      "       -1.2142541 , -1.17510621, -1.17514978, -2.81933084, -1.19610288,\n",
      "       -1.21412248, -1.21420811, -1.1751085 , -1.40300746, -1.36088216,\n",
      "       -1.17801262, -1.17510794, -1.17493134, -1.24535851, -1.17601114,\n",
      "       -1.36143276, -1.17541426, -1.21137811, -1.17510718, -2.80355466]), 'split1_test_score': array([-1.2566212 , -1.2503681 , -1.26575973, -1.39642587, -1.27590179,\n",
      "       -1.27590252, -1.25723311, -1.25758692, -2.4622623 , -2.15385445,\n",
      "       -1.27618158, -1.27590187, -1.25710945, -1.45468242, -1.39642593,\n",
      "       -1.44750594, -1.2571119 , -1.25846463, -1.49637021, -1.25713832,\n",
      "       -1.39742017, -1.25746691, -1.27590188, -1.25661243, -2.50605038]), 'split2_test_score': array([-1.20755045, -1.44493418, -1.21273611, -1.37834973, -1.2267044 ,\n",
      "       -1.22670414, -1.20736093, -1.20773885, -2.1606779 , -1.33036955,\n",
      "       -1.22677638, -1.22670415, -1.20764709, -1.21106672, -1.37834973,\n",
      "       -1.2287468 , -1.20764807, -1.2077749 , -1.42151593, -1.2079447 ,\n",
      "       -1.37793945, -1.2078387 , -1.44983147, -1.2076462 , -2.24890589]), 'split3_test_score': array([-1.17512071, -1.19148667, -1.18561495, -1.36113435, -1.20427459,\n",
      "       -1.2042746 , -1.18667223, -1.33474335, -2.02654321, -1.17782319,\n",
      "       -1.20433014, -1.2042746 , -1.30030877, -1.18495719, -1.36113435,\n",
      "       -1.1894726 , -1.17511988, -1.17434703, -1.60760117, -1.17753848,\n",
      "       -1.36068431, -1.41537193, -1.2042746 , -1.17511874, -2.04261222]), 'split4_test_score': array([-1.12795949, -1.38592344, -1.14017221, -1.30610936, -1.15631169,\n",
      "       -1.1563117 , -1.12759736, -1.12692549, -1.81782399, -1.18743676,\n",
      "       -1.15650822, -1.15631222, -1.12796217, -1.13911197, -1.30610936,\n",
      "       -1.13356793, -1.12796211, -1.12701059, -1.2682074 , -1.12773265,\n",
      "       -1.30577652, -1.12696009, -1.15631169, -1.12796251, -1.82600337]), 'mean_test_score': array([-1.1884723 , -1.33260467, -1.20241872, -1.36057998, -1.2154881 ,\n",
      "       -1.21548941, -1.19079397, -1.22042888, -2.25732765, -1.40911737,\n",
      "       -1.21558376, -1.21548019, -1.2136272 , -1.27856516, -1.36058031,\n",
      "       -1.23546118, -1.18858998, -1.1885057 , -1.40781065, -1.18927306,\n",
      "       -1.36065064, -1.23661038, -1.25953955, -1.18848941, -2.2854253 ]), 'std_test_score': array([0.0424897 , 0.09536033, 0.04075438, 0.03022627, 0.03848311,\n",
      "       0.03848328, 0.04229782, 0.07127782, 0.35031754, 0.3765233 ,\n",
      "       0.03851251, 0.03848321, 0.06043567, 0.12591176, 0.03022629,\n",
      "       0.11027745, 0.04265539, 0.04343256, 0.1369866 , 0.04255614,\n",
      "       0.03053746, 0.09898146, 0.10247777, 0.04249492, 0.34307254]), 'rank_test_score': array([ 1, 18,  7, 19, 10, 11,  6, 13, 24, 23, 12,  9,  8, 17, 20, 14,  4,\n",
      "        3, 22,  5, 21, 15, 16,  2, 25], dtype=int32)}\n",
      "Refit Time: 0.2758920192718506\n",
      "Scorer: make_scorer(mean_absolute_scaled_error, greater_is_better=False)\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: %s' % search.best_score_)\n",
    "print('Best Hyperparameters: %s' % search.best_params_)\n",
    "print('Best Model: %s' % search.best_estimator_)\n",
    "print('Best Index: %s' % search.best_index_)\n",
    "print('CV Results: %s' % search.cv_results_)\n",
    "print('Refit Time: %s' % search.refit_time_)\n",
    "print('Scorer: %s' % search.scorer_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
